{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.models import (\n",
    "    resnet18, ResNet18_Weights,\n",
    "    resnet34, ResNet34_Weights,\n",
    "    resnet50, ResNet50_Weights,\n",
    "    resnet101, ResNet101_Weights,\n",
    "    vit_b_16, ViT_B_16_Weights,\n",
    "    vit_b_32, ViT_B_32_Weights,\n",
    "    vgg16, VGG16_Weights, \n",
    "    vgg16_bn, VGG16_BN_Weights,\n",
    "    convnext_tiny, ConvNeXt_Tiny_Weights,\n",
    "    convnext_base, ConvNeXt_Base_Weights,\n",
    "    efficientnet_v2_s, EfficientNet_V2_S_Weights,\n",
    "    efficientnet_v2_m, EfficientNet_V2_M_Weights\n",
    ")\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision.transforms import Compose, Resize, Lambda, ToTensor, Grayscale, ToPILImage\n",
    "import timm\n",
    "from timm.data import resolve_data_config, create_transform\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn')\n",
    "import PIL\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "rng = np.random.default_rng(0)\n",
    "\n",
    "path_results = os.path.dirname(os.getcwd()) + '/results'\n",
    "path_dataset = os.path.expandvars('$DSDIR/imagenet') # '/scratchf/'\n",
    "path_imagenet_labels = os.path.expandvars('$WORK/DATA/LOC_synset_mapping.txt')\n",
    "path_imagenet100_id = os.path.expandvars('$WORK/DATA/imagenet100.txt')\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "MODEL = 'ResNet50_V2' \n",
    "\n",
    "# TORCHVISION\n",
    "models_and_weights_torchvision = {\n",
    "    'ResNet18': (resnet18, ResNet18_Weights.IMAGENET1K_V1), # same/worse\n",
    "    'ResNet34': (resnet34, ResNet34_Weights.IMAGENET1K_V1), # same/worse\n",
    "    'ResNet50': (resnet50, ResNet50_Weights.IMAGENET1K_V1), # same/worse\n",
    "    'ResNet50_V2': (resnet50, ResNet50_Weights.IMAGENET1K_V2), # better\n",
    "    'ResNet101': (resnet101, ResNet101_Weights.IMAGENET1K_V1), # same/worse\n",
    "    'ResNet101_V2': (resnet101, ResNet101_Weights.IMAGENET1K_V2), # better\n",
    "    'ViT_B_16': (vit_b_16, ViT_B_16_Weights.IMAGENET1K_V1), # better\n",
    "    'ViT_B_16_SWAG_E2E': (vit_b_16, ViT_B_16_Weights.IMAGENET1K_SWAG_E2E_V1), # same/worse\n",
    "    'ViT_B_16_SWAG_LINEAR': (vit_b_16, ViT_B_16_Weights.IMAGENET1K_SWAG_LINEAR_V1), # same/worse\n",
    "    'ViT_B_32': (vit_b_32, ViT_B_32_Weights.IMAGENET1K_V1), # better\n",
    "    'VGG16': (vgg16, VGG16_Weights.IMAGENET1K_V1), # same/worse\n",
    "    'VGG16_BN': (vgg16_bn, VGG16_BN_Weights.IMAGENET1K_V1), # same/worse\n",
    "    'ConvNeXt_Tiny': (convnext_tiny, ConvNeXt_Tiny_Weights.IMAGENET1K_V1), # better\n",
    "    'ConvNeXt_Base': (convnext_base, ConvNeXt_Base_Weights.IMAGENET1K_V1), # better\n",
    "    'EfficientNet_V2_S': (efficientnet_v2_s, EfficientNet_V2_S_Weights.IMAGENET1K_V1), # better\n",
    "    'EfficientNet_V2_M': (efficientnet_v2_m, EfficientNet_V2_M_Weights.IMAGENET1K_V1) # better\n",
    "}\n",
    "\n",
    "# TIMM\n",
    "models_timm = [\n",
    "    'vit_base_patch16_224', # same/worse\n",
    "    'vit_base_patch16_224_in21k', # NEED TO CONVERT IN21K PREDICTIONS TO IN1K\n",
    "    'vit_base_patch16_224_miil', # same/worse\n",
    "    'vit_base_patch16_224_miil_in21k', # NEED TO CONVERT IN21K PREDICTIONS TO IN1K\n",
    "    'vit_base_patch16_384', # same/worse\n",
    "    'vit_base_patch32_224', # same/worse\n",
    "    'vit_base_patch32_224_in21k', # NEED TO CONVERT IN21K PREDICTIONS TO IN1K\n",
    "    'vit_base_patch32_384', # same/worse\n",
    "    ]\n",
    "\n",
    "if MODEL in models_and_weights_torchvision.keys():\n",
    "    TORCHVISION_OR_TIMM = 'torchvision'\n",
    "elif MODEL in models_timm:\n",
    "    TORCHVISION_OR_TIMM = 'timm'\n",
    "else:\n",
    "    raise ValueError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD CLASSIFIER\n",
    "if TORCHVISION_OR_TIMM == 'timm':\n",
    "    classifier = timm.create_model(MODEL, pretrained=True).eval().to(device)\n",
    "    transforms = timm.data.create_transform(**timm.data.resolve_data_config({}, model=classifier))\n",
    "\n",
    "elif TORCHVISION_OR_TIMM == 'torchvision':\n",
    "    model, weights = models_and_weights_torchvision[MODEL]\n",
    "    classifier = model(weights=weights).eval().to(device)\n",
    "    transforms = weights.transforms()\n",
    "\n",
    "\n",
    "# LOAD DATA\n",
    "dataset_train = ImageFolder(path_dataset+'/train', transform=transforms)\n",
    "dataset_val = ImageFolder(path_dataset+'/val', transform=transforms)\n",
    "\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=BATCH_SIZE, num_workers=4, pin_memory=True, shuffle=False) # SHUFFLE FALSE IMPORTANT!\n",
    "dataloader_val = DataLoader(dataset_val, batch_size=BATCH_SIZE, num_workers=4, pin_memory=True, shuffle=False) # SHUFFLE FALSE IMPORTANT!\n",
    "id_to_idx = {}\n",
    "idx_to_label = {}\n",
    "with open(path_imagenet_labels) as f:\n",
    "    for i, line in enumerate(f):\n",
    "        id_to_idx[line[:9]] = i\n",
    "        idx_to_label[i] = line[10:-1]\n",
    "\n",
    "# LOAD CLASSIF OUTPUTS\n",
    "df_train = pd.read_csv(path_results + f'/classif_outputs/{TORCHVISION_OR_TIMM}/classif_outputs_{MODEL}_train.csv', index_col=0)\n",
    "df_val = pd.read_csv(path_results + f'/classif_outputs/{TORCHVISION_OR_TIMM}/classif_outputs_{MODEL}_val.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stats per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_stats_from = 'train'\n",
    "# compute_stats_from = 'val'\n",
    "use_pred_or_label = 'pred'\n",
    "# use_pred_or_label = 'label'\n",
    "\n",
    "if compute_stats_from == 'train':\n",
    "    df = df_train\n",
    "elif compute_stats_from == 'val':\n",
    "    df = df_val\n",
    "else:\n",
    "    raise NotImplementedError()\n",
    "\n",
    "targets = df[use_pred_or_label]\n",
    "\n",
    "acc_per_class = np.empty(1000)\n",
    "mean_msp_per_class = np.empty(1000)\n",
    "std_msp_per_class = np.empty(1000)\n",
    "min_msp_per_class = np.empty(1000)\n",
    "max_msp_per_class = np.empty(1000)\n",
    "mean_tcp_per_class = np.empty(1000)\n",
    "for class_idx in range(1000):\n",
    "    acc_per_class[class_idx] = df.loc[targets == class_idx, 'well_classified'].mean()\n",
    "    mean_msp_per_class[class_idx] = df.loc[targets == class_idx, 'MSP'].mean()\n",
    "    std_msp_per_class[class_idx] = df.loc[targets == class_idx, 'MSP'].std()\n",
    "    min_msp_per_class[class_idx] = df.loc[targets == class_idx, 'MSP'].min()\n",
    "    max_msp_per_class[class_idx] = df.loc[targets == class_idx, 'MSP'].max()\n",
    "    mean_tcp_per_class[class_idx] = df.loc[targets == class_idx, 'TCP'].mean()\n",
    "\n",
    "del df\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(acc_per_class)\n",
    "plt.xlabel('accuracy per class')\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(mean_msp_per_class)\n",
    "plt.xlabel('mean MSP per class')\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(mean_msp_per_class, acc_per_class)\n",
    "plt.xlabel('mean MSP')\n",
    "plt.ylabel('acc')\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(min_msp_per_class, alpha=0.5, label='min MSP')\n",
    "plt.hist(max_msp_per_class, alpha=0.5, label='max MSP')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = df_train[use_pred_or_label]\n",
    "acc_per_class_train = np.empty(1000)\n",
    "for class_idx in range(1000):\n",
    "    acc_per_class_train[class_idx] = df_train.loc[targets == class_idx, 'well_classified'].mean()\n",
    "\n",
    "targets = df_val[use_pred_or_label]\n",
    "acc_per_class_val = np.empty(1000)\n",
    "for class_idx in range(1000):\n",
    "    acc_per_class_val[class_idx] = df_val.loc[targets == class_idx, 'well_classified'].mean()\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(acc_per_class_train, acc_per_class_val)\n",
    "plt.xlabel('acc_per_class_train')\n",
    "plt.ylabel('acc_per_class_val')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selective classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_val\n",
    "\n",
    "# baseline: max softmax\n",
    "domain_cutoff_baseline = np.linspace(0, 1, 1000)\n",
    "coverage_baseline = np.zeros_like(domain_cutoff_baseline)\n",
    "risk_baseline = np.zeros_like(domain_cutoff_baseline)\n",
    "acc_baseline = np.zeros_like(domain_cutoff_baseline)\n",
    "for i, cut in enumerate(domain_cutoff_baseline):\n",
    "    idx_domain = df['MSP'] > cut\n",
    "    coverage_baseline[i] = idx_domain.mean()\n",
    "    acc_baseline[i] = df.loc[idx_domain, 'well_classified'].mean()\n",
    "\n",
    "# plot\n",
    "fig, (ax1) = plt.subplots(1, 1, figsize=(10, 5))\n",
    "ax1.set_title(f'{MODEL} - coverage vs. accuracy')\n",
    "sc = ax1.scatter(coverage_baseline, acc_baseline, c=domain_cutoff_baseline, cmap='viridis')\n",
    "fig.colorbar(sc, ax=ax1, label='MSP threshold')\n",
    "ax1.set_xlabel('coverage')\n",
    "ax1.set_ylabel('accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compare 2 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = df['pred']\n",
    "\n",
    "class_idx = 1\n",
    "# baseline: max softmax\n",
    "domain_cutoff_baseline = np.linspace(0, 1, 1000)\n",
    "coverage_baseline = np.zeros_like(domain_cutoff_baseline)\n",
    "risk_baseline = np.zeros_like(domain_cutoff_baseline)\n",
    "acc_baseline = np.zeros_like(domain_cutoff_baseline)\n",
    "for i, cut in enumerate(domain_cutoff_baseline):\n",
    "    idx_domain = (targets == class_idx) & (df['MSP'] > cut)\n",
    "    coverage_baseline[i] = idx_domain[targets == class_idx].mean()\n",
    "    acc_baseline[i] = df.loc[idx_domain, 'well_classified'].mean()\n",
    "\n",
    "# plot\n",
    "fig, (ax1) = plt.subplots(1, 1, figsize=(10, 5))\n",
    "ax1.set_title(f'{MODEL} - coverage vs. accuracy')\n",
    "sc = ax1.scatter(coverage_baseline, acc_baseline, c=domain_cutoff_baseline, cmap='viridis')\n",
    "fig.colorbar(sc, ax=ax1, label='MSP threshold class 1')\n",
    "ax1.set_xlabel('coverage')\n",
    "ax1.set_ylabel('accuracy')\n",
    "print(acc_per_class_val[class_idx])\n",
    "\n",
    "class_idx = 2\n",
    "# baseline: max softmax\n",
    "domain_cutoff_baseline = np.linspace(0, 1, 1000)\n",
    "coverage_baseline = np.zeros_like(domain_cutoff_baseline)\n",
    "risk_baseline = np.zeros_like(domain_cutoff_baseline)\n",
    "acc_baseline = np.zeros_like(domain_cutoff_baseline)\n",
    "for i, cut in enumerate(domain_cutoff_baseline):\n",
    "    idx_domain = (targets == class_idx) & (df['MSP'] > cut)\n",
    "    coverage_baseline[i] = idx_domain[targets == class_idx].mean()\n",
    "    acc_baseline[i] = df.loc[idx_domain, 'well_classified'].mean()\n",
    "print(acc_per_class_val[class_idx])\n",
    "# plot\n",
    "sc = ax1.scatter(coverage_baseline, acc_baseline, c=domain_cutoff_baseline, cmap='plasma')\n",
    "fig.colorbar(sc, ax=ax1, label='MSP threshold class 2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_pred_or_label = 'pred'\n",
    "targets = df_val[use_pred_or_label].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scaling uses MSP or acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classes = 1000\n",
    "\n",
    "fig, (ax) = plt.subplots(1, 1, figsize=(15, 5))\n",
    "ax.set_title(f'{MODEL} - coverage vs. accuracy')\n",
    "\n",
    "# baseline: max softmax\n",
    "domain_cutoff_baseline = np.linspace(0, 1, 100)\n",
    "coverage_baseline = np.zeros_like(domain_cutoff_baseline)\n",
    "risk_baseline = np.zeros_like(domain_cutoff_baseline)\n",
    "acc_baseline = np.zeros_like(domain_cutoff_baseline)\n",
    "for i, cut in enumerate(domain_cutoff_baseline):\n",
    "    idx_domain = df_val['MSP'] > cut\n",
    "    coverage_baseline[i] = idx_domain.mean()\n",
    "    acc_baseline[i] = df_val.loc[idx_domain, 'well_classified'].mean()\n",
    "# plot\n",
    "sc = ax.scatter(coverage_baseline, acc_baseline, c=domain_cutoff_baseline, cmap='Greys', vmin=0, vmax=1)\n",
    "fig.colorbar(sc, ax=ax, label='MSP threshold')\n",
    "ax.set_xlabel('coverage')\n",
    "ax.set_ylabel('accuracy')\n",
    "\n",
    "\n",
    "# domain_cutoff_baseline = np.linspace(0, 1, 100)\n",
    "# coverage_baseline = np.zeros_like(domain_cutoff_baseline)\n",
    "# risk_baseline = np.zeros_like(domain_cutoff_baseline)\n",
    "# acc_baseline = np.zeros_like(domain_cutoff_baseline)\n",
    "# for i, cut in enumerate(domain_cutoff_baseline):\n",
    "#     k = mean_msp_per_class[targets] / mean_msp_per_class.max()\n",
    "#     idx_domain = k * df_val['MSP'] > cut\n",
    "#     coverage_baseline[i] = idx_domain.mean()\n",
    "#     acc_baseline[i] = df_val.loc[idx_domain, 'well_classified'].mean()\n",
    "# # plot\n",
    "# sc = ax.scatter(coverage_baseline, acc_baseline, c=domain_cutoff_baseline, cmap='Purples', vmin=0, vmax=1, marker='+')\n",
    "# fig.colorbar(sc, ax=ax, label='MSP threshold - scale with mean class MSP')\n",
    "# ax.set_xlabel('coverage')\n",
    "# ax.set_ylabel('accuracy')\n",
    "\n",
    "\n",
    "domain_cutoff_baseline = np.linspace(0, 1, 100)\n",
    "coverage_baseline = np.zeros_like(domain_cutoff_baseline)\n",
    "risk_baseline = np.zeros_like(domain_cutoff_baseline)\n",
    "acc_baseline = np.zeros_like(domain_cutoff_baseline)\n",
    "for i, cut in enumerate(domain_cutoff_baseline):\n",
    "    # k = 1 + 2*(acc_per_class[targets] - acc_per_class.mean())\n",
    "    k = acc_per_class[targets] / acc_per_class.max()\n",
    "    idx_domain = k * df_val['MSP'] > cut\n",
    "    coverage_baseline[i] = idx_domain.mean()\n",
    "    acc_baseline[i] = df_val.loc[idx_domain, 'well_classified'].mean()\n",
    "# plot\n",
    "sc = ax.scatter(coverage_baseline, acc_baseline, c=domain_cutoff_baseline, cmap='Greens', vmin=0, vmax=1, marker='+')\n",
    "fig.colorbar(sc, ax=ax, label='MSP threshold - scale with mean class acc')\n",
    "ax.set_xlabel('coverage')\n",
    "ax.set_ylabel('accuracy')\n",
    "\n",
    "\n",
    "# domain_cutoff_baseline = np.linspace(0, 1, 100)\n",
    "# coverage_baseline = np.zeros_like(domain_cutoff_baseline)\n",
    "# risk_baseline = np.zeros_like(domain_cutoff_baseline)\n",
    "# acc_baseline = np.zeros_like(domain_cutoff_baseline)\n",
    "# for i, cut in enumerate(domain_cutoff_baseline):\n",
    "#     k = 1 / (acc_per_class[targets] / mean_msp_per_class[targets])\n",
    "#     idx_domain = k * df_val['MSP'] > cut\n",
    "#     coverage_baseline[i] = idx_domain.mean()\n",
    "#     acc_baseline[i] = df_val.loc[idx_domain, 'well_classified'].mean()\n",
    "# # plot\n",
    "# sc = ax.scatter(coverage_baseline, acc_baseline, c=domain_cutoff_baseline, cmap='Reds', vmin=0, vmax=1, marker='+')\n",
    "# fig.colorbar(sc, ax=ax, label='MSP threshold - tests')\n",
    "# ax.set_xlabel('coverage')\n",
    "# ax.set_ylabel('accuracy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax) = plt.subplots(1, 1, figsize=(15, 5))\n",
    "ax.set_title(f'{MODEL} - coverage vs. accuracy')\n",
    "\n",
    "# baseline: max softmax\n",
    "domain_cutoff_baseline = np.linspace(0, 1, 100)\n",
    "coverage_baseline = np.zeros_like(domain_cutoff_baseline)\n",
    "risk_baseline = np.zeros_like(domain_cutoff_baseline)\n",
    "acc_baseline = np.zeros_like(domain_cutoff_baseline)\n",
    "for i, cut in enumerate(domain_cutoff_baseline):\n",
    "    idx_domain = df_val['MSP'] > cut\n",
    "    coverage_baseline[i] = idx_domain.mean()\n",
    "    acc_baseline[i] = df_val.loc[idx_domain, 'well_classified'].mean()\n",
    "# plot\n",
    "sc = ax.scatter(coverage_baseline, acc_baseline, c=domain_cutoff_baseline, cmap='Greys', vmin=0, vmax=1)\n",
    "fig.colorbar(sc, ax=ax, label='MSP threshold')\n",
    "ax.set_xlabel('coverage')\n",
    "ax.set_ylabel('accuracy')\n",
    "\n",
    "\n",
    "# domain_cutoff_baseline = np.linspace(-1, 1, 100)\n",
    "# coverage_baseline = np.zeros_like(domain_cutoff_baseline)\n",
    "# risk_baseline = np.zeros_like(domain_cutoff_baseline)\n",
    "# acc_baseline = np.zeros_like(domain_cutoff_baseline)\n",
    "# for i, cut in enumerate(domain_cutoff_baseline):\n",
    "#     idx_domain = (df_val['MSP'] - mean_msp_per_class[targets]) / std_msp_per_class[targets] > cut\n",
    "#     coverage_baseline[i] = idx_domain.mean()\n",
    "#     acc_baseline[i] = df_val.loc[idx_domain, 'well_classified'].mean()\n",
    "# # plot\n",
    "# sc = ax.scatter(coverage_baseline, acc_baseline, c=domain_cutoff_baseline, cmap='Purples', vmin=0, vmax=1, marker='+')\n",
    "# fig.colorbar(sc, ax=ax, label='MSP threshold - select per class (normalize mean std)')\n",
    "# ax.set_xlabel('coverage')\n",
    "# ax.set_ylabel('accuracy')\n",
    "\n",
    "\n",
    "domain_cutoff_baseline = np.linspace(0, 1, 100)\n",
    "coverage_baseline = np.zeros_like(domain_cutoff_baseline)\n",
    "risk_baseline = np.zeros_like(domain_cutoff_baseline)\n",
    "acc_baseline = np.zeros_like(domain_cutoff_baseline)\n",
    "for i, cut in enumerate(domain_cutoff_baseline):\n",
    "    idx_domain = (df_val['MSP'] - min_msp_per_class[targets]) / (max_msp_per_class[targets] - min_msp_per_class[targets]) > cut\n",
    "    coverage_baseline[i] = idx_domain.mean()\n",
    "    acc_baseline[i] = df_val.loc[idx_domain, 'well_classified'].mean()\n",
    "# plot\n",
    "sc = ax.scatter(coverage_baseline, acc_baseline, c=domain_cutoff_baseline, cmap='Blues', vmin=0, vmax=1, marker='+')\n",
    "fig.colorbar(sc, ax=ax, label='MSP threshold - select per class (normalize min max)')\n",
    "ax.set_xlabel('coverage')\n",
    "ax.set_ylabel('accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vs. Geifman 2017 Selective Classification for Deep Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax) = plt.subplots(1, 1, figsize=(10, 5))\n",
    "ax.set_title(f'{MODEL} - coverage vs. risk')\n",
    "\n",
    "# baseline: max softmax\n",
    "domain_cutoff_baseline = np.linspace(0, 1, 100)\n",
    "coverage_baseline = np.zeros_like(domain_cutoff_baseline)\n",
    "risk_baseline = np.zeros_like(domain_cutoff_baseline)\n",
    "acc_baseline = np.zeros_like(domain_cutoff_baseline)\n",
    "for i, cut in enumerate(domain_cutoff_baseline):\n",
    "    idx_domain = df_val['MSP'] > cut\n",
    "    coverage_baseline[i] = idx_domain.mean()\n",
    "    acc_baseline[i] = df_val.loc[idx_domain, 'well_classified'].mean()\n",
    "# plot\n",
    "sc = ax.scatter(coverage_baseline, 1-acc_baseline, c=domain_cutoff_baseline, cmap='Greys', vmin=0, vmax=1)\n",
    "fig.colorbar(sc, ax=ax, label='MSP threshold')\n",
    "ax.set_xlabel('coverage')\n",
    "ax.set_ylabel('risk')\n",
    "\n",
    "domain_cutoff_baseline = np.linspace(0, 1, 100)\n",
    "coverage_baseline = np.zeros_like(domain_cutoff_baseline)\n",
    "risk_baseline = np.zeros_like(domain_cutoff_baseline)\n",
    "acc_baseline = np.zeros_like(domain_cutoff_baseline)\n",
    "for i, cut in enumerate(domain_cutoff_baseline):\n",
    "    k = acc_per_class[targets]\n",
    "    idx_domain = k * df_val['MSP'] > cut\n",
    "    coverage_baseline[i] = idx_domain.mean()\n",
    "    acc_baseline[i] = df_val.loc[idx_domain, 'well_classified'].mean()\n",
    "# plot\n",
    "sc = ax.scatter(coverage_baseline, 1 - acc_baseline, c=domain_cutoff_baseline, cmap='Greens', vmin=0, vmax=1, marker='+')\n",
    "fig.colorbar(sc, ax=ax, label='MSP threshold - scale with mean class acc')\n",
    "\n",
    "\n",
    "coverage = np.array([0.2585, 0.4878, 0.6502, 0.7676, 0.8677, 0.9614])\n",
    "risk = np.array([0.0164, 0.0474, 0.0988, 0.1475, 0.1955, 0.2451])\n",
    "ax.scatter(coverage, risk, label='Geifman 2017')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vs. Feng 2023 \"Towards better selective classification\" on ImageNet-100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet100_idx = []\n",
    "with open(path_imagenet100_id) as f:\n",
    "    for line in f:\n",
    "        imagenet100_idx.append(id_to_idx[line[:-1]])\n",
    "        \n",
    "idx_classes_imagenet100 = df_val.index[df_val['label'].isin(imagenet100_idx)]\n",
    "df_val.loc[idx_classes_imagenet100, 'well_classified'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax) = plt.subplots(1, 1, figsize=(10, 5))\n",
    "ax.set_title(f'{MODEL} - coverage vs. risk - ImageNet-100')\n",
    "\n",
    "# baseline: max softmax\n",
    "domain_cutoff_baseline = np.linspace(0, 1, 100)\n",
    "coverage_baseline = np.zeros_like(domain_cutoff_baseline)\n",
    "risk_baseline = np.zeros_like(domain_cutoff_baseline)\n",
    "acc_baseline = np.zeros_like(domain_cutoff_baseline)\n",
    "for i, cut in enumerate(domain_cutoff_baseline):\n",
    "    idx_domain = (df_val['MSP'] > cut) & (df_val.index.isin(idx_classes_imagenet100))\n",
    "    coverage_baseline[i] = idx_domain[idx_classes_imagenet100].mean()\n",
    "    acc_baseline[i] = df_val.loc[idx_domain, 'well_classified'].mean()\n",
    "# plot\n",
    "sc = ax.scatter(coverage_baseline, 1 - acc_baseline, c=domain_cutoff_baseline, cmap='Greys', vmin=0, vmax=1)\n",
    "fig.colorbar(sc, ax=ax, label='MSP threshold')\n",
    "ax.set_xlabel('coverage')\n",
    "ax.set_ylabel('risk')\n",
    "\n",
    "\n",
    "domain_cutoff_baseline = np.linspace(0, 1, 100)\n",
    "coverage_baseline = np.zeros_like(domain_cutoff_baseline)\n",
    "risk_baseline = np.zeros_like(domain_cutoff_baseline)\n",
    "acc_baseline = np.zeros_like(domain_cutoff_baseline)\n",
    "for i, cut in enumerate(domain_cutoff_baseline):\n",
    "    k = acc_per_class[targets]\n",
    "    idx_domain = (k * df_val['MSP'] > cut) & (df_val.index.isin(idx_classes_imagenet100))\n",
    "    coverage_baseline[i] = idx_domain[idx_classes_imagenet100].mean()\n",
    "    acc_baseline[i] = df_val.loc[idx_domain, 'well_classified'].mean()\n",
    "# plot\n",
    "sc = ax.scatter(coverage_baseline, 1 - acc_baseline, c=domain_cutoff_baseline, cmap='Greens', vmin=0, vmax=1, marker='+')\n",
    "fig.colorbar(sc, ax=ax, label='MSP threshold - select per class (acc3)')\n",
    "ax.set_xlabel('coverage')\n",
    "ax.set_ylabel('risk')\n",
    "\n",
    "\n",
    "coverage = np.arange(100, 20, -10) / 100\n",
    "risk_vanilla = np.array([14.32, 8.96, 4.99, 2.83, 1.7, 1.08, 0.77, 0.60]) / 100\n",
    "risk_SN = np.array([13.77, 9.44, 6.0, 3.38, 1.99, 1.05, 0.58, 1.04]) / 100\n",
    "risk_SNSR = np.array([13.77, 7.89, 4.47, 2.21, 1.57, 0.85, 0.53, 0.64]) / 100\n",
    "\n",
    "ax.scatter(coverage, risk_vanilla, label='vanilla')\n",
    "ax.scatter(coverage, risk_SN, label='SN')\n",
    "ax.scatter(coverage, risk_SNSR, label='SNSR')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check labels from ImageNet100 are correct and check if images come from validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet100_labels = [idx_to_label[i] for i in imagenet100_idx]\n",
    "\n",
    "class_chosen = [i for i in idx_to_label if idx_to_label[i] == 'Doberman, Doberman pinscher'][0]\n",
    "imagenet100_idx_class_chosen = (df_val.index[np.array(dataset_val.targets) == class_chosen]).tolist()\n",
    "\n",
    "dataset_imagenet100_val = Subset(dataset_val, imagenet100_idx_class_chosen)\n",
    "\n",
    "figure = plt.figure(figsize=(10, 20))\n",
    "cols, rows = 5, 10\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = i - 1\n",
    "    img, label = dataset_imagenet100_val[sample_idx]\n",
    "    pred = classifier(img.to(device).unsqueeze(0)).argmax(dim=1).item()\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(f'real: {idx_to_label[label]}\\npred: {idx_to_label[pred]}', fontsize=10)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow((0.2*img+0.4).permute(1, 2, 0), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./benchmarking-uncertainty-estimation-performance-main/utils')\n",
    "from uncertainty_metrics import AUROC, coverage_for_desired_accuracy, ECE_calc, AURC_calc\n",
    "\n",
    "def metrics_calculations(samples_certainties, num_bins_ece=15):\n",
    "    # Note: we assume here the certainty scores in samples_certainties are probabilities.\n",
    "    results = {}\n",
    "    results['Accuracy'] = (samples_certainties[:,1].sum() / samples_certainties.shape[0]).item() * 100\n",
    "    results['AUROC'] = AUROC(samples_certainties)\n",
    "    results['Coverage_for_Accuracy_99'] = coverage_for_desired_accuracy(samples_certainties, accuracy=0.99, start_index=200)\n",
    "    ece, mce = ECE_calc(samples_certainties, num_bins=num_bins_ece)\n",
    "    results[f'ECE_{num_bins_ece}'] = ece.item()\n",
    "    results['AURC'] = AURC_calc(samples_certainties)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_certainties = torch.cat((torch.tensor(df_val['MSP']).unsqueeze(1), torch.tensor(df_val['well_classified']).unsqueeze(1)), dim=1)\n",
    "indices_sorting_by_confidence = torch.argsort(samples_certainties[:, 0], descending=True)\n",
    "samples_certainties = samples_certainties[indices_sorting_by_confidence]\n",
    "res = metrics_calculations(samples_certainties)\n",
    "print('original', res)\n",
    "\n",
    "accuracies = []\n",
    "coverages = []\n",
    "for acc in np.arange(res['Accuracy']/100+0.001, 1, 0.001):\n",
    "    cov = coverage_for_desired_accuracy(samples_certainties, accuracy=acc, start_index=200)\n",
    "    accuracies.append(acc)\n",
    "    coverages.append(cov)\n",
    "plt.figure()\n",
    "plt.plot(coverages, accuracies, label='original')\n",
    "\n",
    "\n",
    "use_pred_or_label = 'pred'\n",
    "targets = df_val[use_pred_or_label].tolist()\n",
    "k = acc_per_class[targets] / acc_per_class.max()\n",
    "\n",
    "samples_certainties = torch.cat((torch.tensor(k * df_val['MSP']).unsqueeze(1), torch.tensor(df_val['well_classified']).unsqueeze(1)), dim=1)\n",
    "indices_sorting_by_confidence = torch.argsort(samples_certainties[:, 0], descending=True)\n",
    "samples_certainties = samples_certainties[indices_sorting_by_confidence]\n",
    "res = metrics_calculations(samples_certainties)\n",
    "print('after scaling MSP', res)\n",
    "\n",
    "accuracies = []\n",
    "coverages = []\n",
    "for acc in np.arange(res['Accuracy']/100+0.001, 1, 0.001):\n",
    "    cov = coverage_for_desired_accuracy(samples_certainties, accuracy=acc, start_index=200)\n",
    "    accuracies.append(acc)\n",
    "    coverages.append(cov)\n",
    "plt.plot(coverages, accuracies, label='after scaling MSP')\n",
    "plt.legend();"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test threshold on logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_val\n",
    "\n",
    "i = 0\n",
    "for x, y in dataloader_val:\n",
    "    with torch.no_grad():\n",
    "        logits = classifier(x.to(device))\n",
    "    max_logits = logits.max(axis=1).values\n",
    "    msp = torch.softmax(logits, axis=1).max(axis=1).values\n",
    "    df.loc[i:i+max_logits.shape[0]-1, 'max_logit'] = max_logits.cpu().numpy()\n",
    "    df.loc[i:i+max_logits.shape[0]-1, 'msp_calc'] = msp.cpu().numpy()\n",
    "    i += max_logits.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline: max softmax\n",
    "domain_cutoff_baseline = np.linspace(0, 1, 1000)\n",
    "coverage_baseline = np.zeros_like(domain_cutoff_baseline)\n",
    "risk_baseline = np.zeros_like(domain_cutoff_baseline)\n",
    "acc_baseline = np.zeros_like(domain_cutoff_baseline)\n",
    "for i, cut in enumerate(domain_cutoff_baseline):\n",
    "    idx_domain = df['msp_calc'] > cut\n",
    "    coverage_baseline[i] = idx_domain.mean()\n",
    "    acc_baseline[i] = df.loc[idx_domain, 'well_classified'].mean()\n",
    "\n",
    "# max logit\n",
    "domain_cutoff = np.linspace(df['max_logit'].min(), df['max_logit'].max(), 1000)\n",
    "coverage = np.zeros_like(domain_cutoff)\n",
    "risk_ = np.zeros_like(domain_cutoff)\n",
    "acc = np.zeros_like(domain_cutoff)\n",
    "for i, cut in enumerate(domain_cutoff):\n",
    "    idx_domain = df['max_logit'] > cut\n",
    "    coverage[i] = idx_domain.mean()\n",
    "    acc[i] = df.loc[idx_domain, 'well_classified'].mean()\n",
    "\n",
    "# plot\n",
    "fig, (ax1) = plt.subplots(1, 1, figsize=(10, 5))\n",
    "ax1.set_title(f'{MODEL} - coverage vs. accuracy')\n",
    "sc1 = ax1.scatter(coverage_baseline, acc_baseline, c=domain_cutoff_baseline, cmap='viridis')\n",
    "sc2 = ax1.scatter(coverage, acc, c=domain_cutoff, cmap='plasma')\n",
    "fig.colorbar(sc1, ax=ax1, label='MSP threshold')\n",
    "fig.colorbar(sc2, ax=ax1, label='max_logit threshold')\n",
    "ax1.set_xlabel('coverage')\n",
    "ax1.set_ylabel('accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "c522a5618233109531e8d8fb7f5c3011399924e76f9423af51315557ed1c4c11"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
