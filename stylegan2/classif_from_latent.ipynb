{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import json\n",
    "import PIL.Image\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.utils as vutils\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pytorch_lightning as pl\n",
    "import torchvision\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "from sklearn.decomposition import PCA, IncrementalPCA\n",
    "from sklearn.manifold import TSNE\n",
    "from scipy.stats import wasserstein_distance\n",
    "import numpy as np\n",
    "import functools\n",
    "import pandas as pd\n",
    "# from tqdm import tqdm\n",
    "\n",
    "\n",
    "from stylegan2_ada_pytorch.torch_utils import misc\n",
    "import stylegan2_ada_pytorch.dnnlib\n",
    "import stylegan2_ada_pytorch.legacy\n",
    "from stylegan2_ada_pytorch.projector import project\n",
    "from stylegan2_ada_pytorch.training.dataset import ImageFolderDataset\n",
    "from classifiers.models import CNN_MNIST\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "path_results = Path.cwd().parent / 'results'\n",
    "# path_results = Path('w:/results/stylegan2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess_images(images):\n",
    "    assert images.dim() == 4, \"Expected 4D (B x C x H x W) image tensor, got {}D\".format(images.dim())\n",
    "    # lo, hi = [-1, 1] # generator scale\n",
    "    # images = (images - lo) * (255 / (hi - lo)) # classifier scale\n",
    "    # images = torch.round(images.clamp(0, 255))#.to(torch.uint8).to(torch.float)\n",
    "    # images = (images * 127.5 + 128).clamp(0, 255)\n",
    "    images = ((images + 1) / 2).clamp(0, 1)\n",
    "    images = images[:, :, 2:30, 2:30] # remove padding\n",
    "\n",
    "    return images\n",
    "\n",
    "def plot_images(images, title=''):\n",
    "    images = images * 255\n",
    "    images = images.to(torch.uint8)\n",
    "    plt.figure()\n",
    "    plt.imshow(vutils.make_grid(images.cpu(), pad_value=255).permute(1,2,0), vmin=0, vmax=255)\n",
    "    plt.axis('off')\n",
    "    plt.grid(False)\n",
    "    plt.title(title)\n",
    "\n",
    "\n",
    "def generate_from_z(z):\n",
    "    for i in np.arange(0, z.shape[0], batch_size):\n",
    "        img = G(z[i:i+batch_size], c=None, noise_mode='const', force_fp32=True)\n",
    "        if i == 0: \n",
    "            imgs = img\n",
    "        else:\n",
    "            imgs = torch.cat((imgs, img))\n",
    "    return imgs\n",
    "\n",
    "\n",
    "def plot_random_images(imgs):\n",
    "    # from generate.py: img = (img.permute(0, 2, 3, 1) * 127.5 + 128).clamp(0, 255).to(torch.uint8)[0].cpu().numpy()\n",
    "    # imgs = (imgs * 127.5 + 128).clamp(0, 255).to(torch.uint8)\n",
    "    imgs = postprocess_images(imgs)\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(vutils.make_grid(imgs[torch.randint(0, imgs.shape[0], (100,))].cpu(), pad_value=255, nrow=10).permute(1,2,0))\n",
    "\n",
    "def plot_images_from_s(s):\n",
    "    imgs = generate_img_from_s(s)\n",
    "    imgs = postprocess_images(imgs)\n",
    "    plot_images(imgs)\n",
    "    \n",
    "def truncate(x, x_avg, psi):\n",
    "    # psi=0 means we get average value, \n",
    "    # psi=1 we get original value, \n",
    "    # 0<psi<1 we get interpolation between mean and original\n",
    "    return x_avg.lerp(x, psi)\n",
    "\n",
    "\n",
    "def styleSpace_dict2vec(styleSpace_dict):\n",
    "    styleSpace_vec = []\n",
    "    for res in G.synthesis.block_resolutions:\n",
    "        for layer in ['conv0', 'conv1', 'torgb']:\n",
    "            if res == 4 and layer == 'conv0': continue\n",
    "            key = f'b{res}.{layer}'\n",
    "            values = styleSpace_dict[key]\n",
    "            if values.dim() == 1: values = values.unsqueeze(0)\n",
    "            styleSpace_vec.append(values)\n",
    "    styleSpace_vec = torch.cat(styleSpace_vec, dim=1)\n",
    "    return styleSpace_vec\n",
    "\n",
    "\n",
    "def styleSpace_vec2dict(styleSpace_vec):\n",
    "    if styleSpace_vec.dim() == 1:\n",
    "        styleSpace_vec = styleSpace_vec.unsqueeze(0)\n",
    "    styleSpace_dict = {}\n",
    "    dim_base = 0\n",
    "    for res in G.synthesis.block_resolutions:\n",
    "        block = getattr(G.synthesis, f'b{res}')\n",
    "        for layer in ['conv0', 'conv1', 'torgb']:\n",
    "            if res == 4 and layer == 'conv0': continue\n",
    "            block_layer = getattr(block, layer)\n",
    "            dim_size = block_layer.affine.weight.shape[1]\n",
    "            key = f'b{res}.{layer}'\n",
    "            styleSpace_dict[key] = styleSpace_vec[:, dim_base:dim_base+dim_size]#.squeeze()\n",
    "            dim_base += dim_size\n",
    "    assert dim_base == styleSpace_vec.shape[1]\n",
    "    return styleSpace_dict\n",
    "\n",
    "\n",
    "def compute_styleSpace_vec_idx2coord():\n",
    "    vec_idx2coord = {}\n",
    "    idx = 0\n",
    "    for res in G.synthesis.block_resolutions:\n",
    "        block = getattr(G.synthesis, f'b{res}')\n",
    "        for layer in ['conv0', 'conv1', 'torgb']:\n",
    "            if res == 4 and layer == 'conv0': continue\n",
    "            block_layer = getattr(block, layer)\n",
    "            dim_size = block_layer.affine.weight.shape[1]\n",
    "            for dim in range(dim_size):\n",
    "                vec_idx2coord[idx] = (f'b{res}.{layer}', dim)\n",
    "                idx += 1\n",
    "    return vec_idx2coord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best FID: 1.63 ; best model : network-snapshot-008467.pkl\n"
     ]
    }
   ],
   "source": [
    "# path_model = 'https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/afhqcat.pkl'\n",
    "# path_model = 'https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/afhqdog.pkl'\n",
    "# path_model = 'https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/afhqwild.pkl'\n",
    "# path_model = 'https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/brecahad.pkl'\n",
    "# path_model = 'https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/cifar10.pkl'\n",
    "# path_model = 'https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/ffhq.pkl'\n",
    "# path_model = 'https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/metfaces.pkl'\n",
    "\n",
    "# path_model = path_results / 'stylegan2-training-runs' / '00011-mnist_stylegan2_noise-cond-auto4-original'\n",
    "# path_model = path_results / 'stylegan2-training-runs' / '00015-mnist_stylegan2_blur_noise-cond-auto4'\n",
    "path_model = path_results / 'stylegan2-training-runs' / '00016-mnist_stylegan2_blur_noise_maxSeverity3_proba50-cond-auto4'\n",
    "\n",
    "# find best model in folder\n",
    "if not str(path_model).endswith('pkl'): # local files\n",
    "    with open(path_model / 'metric-fid50k_full.jsonl', 'r') as json_file:\n",
    "        json_list = list(json_file)\n",
    "\n",
    "    best_fid = 1e6\n",
    "    for json_str in json_list:\n",
    "        json_line = json.loads(json_str)\n",
    "        if json_line['results']['fid50k_full'] < best_fid:\n",
    "            best_fid = json_line['results']['fid50k_full']\n",
    "            best_model = json_line['snapshot_pkl']\n",
    "    print('Best FID: {:.2f} ; best model : {}'.format(best_fid, best_model))\n",
    "    path_model = path_model / best_model\n",
    "\n",
    "    with open(path_model, 'rb') as f:\n",
    "        G = pickle.load(f)['G_ema'].to(device)  # torch.nn.Module\n",
    "\n",
    "else: # download pre-trained\n",
    "    with dnnlib.util.open_url(path_model) as f:\n",
    "        G = legacy.load_network_pkl(f)['G_ema'].to(device)\n",
    "\n",
    "if device == 'cpu': G.forward = functools.partial(G.forward, force_fp32=True)\n",
    "\n",
    "conditional = G.c_dim > 0\n",
    "\n",
    "# registor hooks to save intermediate values (images and style space)\n",
    "intermediate_images_torgb = {}\n",
    "def get_torgb(name):\n",
    "    def hook(module, input, output):\n",
    "        intermediate_images_torgb[name] = output.detach()\n",
    "    return hook\n",
    "intermediate_images_block = {}\n",
    "def get_block_img(name):\n",
    "    def hook(module, input, output):\n",
    "        intermediate_images_block[name] = output[1].detach()\n",
    "    return hook\n",
    "styleSpace_values = {}\n",
    "def get_styleSpace_values(name):\n",
    "    def hook(module, input, output):\n",
    "        styleSpace_values[name] = output.detach()\n",
    "    return hook\n",
    "for res in G.synthesis.block_resolutions:\n",
    "    block = getattr(G.synthesis, f'b{res}')\n",
    "    block.torgb.register_forward_hook(get_torgb(res))\n",
    "    block.register_forward_hook(get_block_img(res))\n",
    "    for layer in ['conv0', 'conv1', 'torgb']:\n",
    "        if res == 4 and layer == 'conv0': continue\n",
    "        block_layer = getattr(block, layer)\n",
    "        block_layer.affine.register_forward_hook(get_styleSpace_values(name=f'b{res}.{layer}'))\n",
    "\n",
    "        \n",
    "# backward hooks to get gradients relative to styleSpace\n",
    "styleSpace_grads = {}\n",
    "def get_styleSpace_grads(name):\n",
    "    def hook(self, grad_input, grad_output):\n",
    "        styleSpace_grads[name] = grad_output[0].detach()\n",
    "    return hook\n",
    "\n",
    "for res in G.synthesis.block_resolutions:\n",
    "    block = getattr(G.synthesis, f'b{res}')\n",
    "    block.torgb.register_forward_hook(get_torgb(res))\n",
    "    block.register_forward_hook(get_block_img(res))\n",
    "    for layer in ['conv0', 'conv1', 'torgb']:\n",
    "        if res == 4 and layer == 'conv0': continue\n",
    "        block_layer = getattr(block, layer)\n",
    "        block_layer.affine.register_full_backward_hook(get_styleSpace_grads(name=f'b{res}.{layer}'))\n",
    "\n",
    "        \n",
    "# dict to convert index to coordinate for stylespace vectors\n",
    "styleSpace_vec_idx2coord = compute_styleSpace_vec_idx2coord()\n",
    "\n",
    "\n",
    "# function to move a given style dimension\n",
    "def generate_img_new_style(ws, block_layer_name, index=0, direction=1):\n",
    "    def move_style(index, direction):\n",
    "        def hook(module, input, output):\n",
    "            output[:, index] += direction\n",
    "            return output\n",
    "        return hook\n",
    "\n",
    "    block_name, layer_name = block_layer_name.split('.')\n",
    "    block = getattr(G.synthesis, block_name)\n",
    "    block_layer = getattr(block, layer_name)\n",
    "    handle = block_layer.affine.register_forward_hook(move_style(index, direction))\n",
    "\n",
    "    if ws.dim() == 2:\n",
    "        ws = ws.unsqueeze(1).repeat((1, G.num_ws, 1))\n",
    "    img = G.synthesis(ws, noise_mode='const', force_fp32=True)\n",
    "\n",
    "    handle.remove()\n",
    "\n",
    "    return img\n",
    "    \n",
    "    \n",
    "# function to modify a given style dimension\n",
    "def generate_img_new_style2(ws, block_layer_name, index, s_style_min, s_style_max, s_shift=1, positive_direction=True):\n",
    "    def move_style(index, weight_shift):\n",
    "        def hook(module, input, output):\n",
    "            output[:, index] += weight_shift\n",
    "            return output\n",
    "        return hook\n",
    "    \n",
    "    assert type(index) == int, 'Function only works for 1 style'\n",
    "    assert ws.shape[0] == 1, 'Works only for 1 image' # orig_value only for 1 image\n",
    "    \n",
    "    if ws.dim() == 2:\n",
    "        ws = ws.unsqueeze(1).repeat((1, G.num_ws, 1))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        G.synthesis(ws, noise_mode='const', force_fp32=True) # first pass to get style vector from hook\n",
    "    orig_value = styleSpace_values[block_layer_name][0, index]\n",
    "    target_value = (s_style_max if positive_direction else s_style_min)\n",
    "    weight_shift = s_shift * (target_value - orig_value)\n",
    "\n",
    "    block_name, layer_name = block_layer_name.split('.')\n",
    "    block = getattr(G.synthesis, block_name)\n",
    "    block_layer = getattr(block, layer_name)\n",
    "    handle = block_layer.affine.register_forward_hook(move_style(index, weight_shift))\n",
    "    \n",
    "    img = G.synthesis(ws, noise_mode='const', force_fp32=True)\n",
    "\n",
    "    handle.remove()\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "# function to modify a given style dimension\n",
    "def generate_img_new_style3(ws, block_layer_name, index, s_std, strength=5, positive_direction=True):\n",
    "    def move_style(index, weight_shift):\n",
    "        def hook(module, input, output):\n",
    "            output[:, index] += weight_shift\n",
    "            return output\n",
    "        return hook\n",
    "    \n",
    "    assert type(index) == int, 'Function only works for 1 style'\n",
    "    assert ws.shape[0] == 1, 'Works only for 1 image'\n",
    "    \n",
    "    if ws.dim() == 2:\n",
    "        ws = ws.unsqueeze(1).repeat((1, G.num_ws, 1))\n",
    "    \n",
    "    d = 1 if positive_direction else -1\n",
    "    weight_shift = d * strength * s_std\n",
    "\n",
    "    block_name, layer_name = block_layer_name.split('.')\n",
    "    block = getattr(G.synthesis, block_name)\n",
    "    block_layer = getattr(block, layer_name)\n",
    "    handle = block_layer.affine.register_forward_hook(move_style(index, weight_shift))\n",
    "    \n",
    "    img = G.synthesis(ws, noise_mode='const', force_fp32=True)\n",
    "\n",
    "    handle.remove()\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "# function to generate image from S\n",
    "def generate_img_from_s(s):\n",
    "    def set_style(values):\n",
    "        def hook(module, input, output):\n",
    "            output = values\n",
    "            return output\n",
    "        return hook\n",
    "    \n",
    "    if type(s) != dict: s = styleSpace_vec2dict(s)\n",
    "    assert s['b4.conv1'].dim() == 2, 'Should be of 2 dimensions: batch_size x s_dim'\n",
    "    batch_size = s['b4.conv1'].shape[0]\n",
    "    \n",
    "    handles = []\n",
    "    for res in G.synthesis.block_resolutions:\n",
    "        block = getattr(G.synthesis, f'b{res}')\n",
    "        for layer in ['conv0', 'conv1', 'torgb']:\n",
    "            if res == 4 and layer == 'conv0': continue\n",
    "            block_layer = getattr(block, layer)\n",
    "            values = s[f'b{res}.{layer}']\n",
    "            handles.append(block_layer.affine.register_forward_hook(set_style(values)))\n",
    "    \n",
    "    dummy_ws = torch.zeros((batch_size, G.num_ws, G.w_dim), device=device)\n",
    "    img = G.synthesis(dummy_ws, noise_mode='const', force_fp32=True)\n",
    "\n",
    "    for h in handles: h.remove()\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
      "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
      "\n",
      "Generator            Parameters  Buffers  Output shape      Datatype\n",
      "---                  ---         ---      ---               ---     \n",
      "mapping.embed        5632        -        [5, 512]          float32 \n",
      "mapping.fc0          524800      -        [5, 512]          float32 \n",
      "mapping.fc1          262656      -        [5, 512]          float32 \n",
      "mapping              -           512      [5, 8, 512]       float32 \n",
      "synthesis.b4.conv1   2622465     32       [5, 512, 4, 4]    float32 \n",
      "synthesis.b4.torgb   263169      -        [5, 1, 4, 4]      float32 \n",
      "synthesis.b4:0       8192        16       [5, 512, 4, 4]    float32 \n",
      "synthesis.b4:1       -           -        [5, 512, 4, 4]    float32 \n",
      "synthesis.b8.conv0   2622465     80       [5, 512, 8, 8]    float16 \n",
      "synthesis.b8.conv1   2622465     80       [5, 512, 8, 8]    float16 \n",
      "synthesis.b8.torgb   263169      -        [5, 1, 8, 8]      float16 \n",
      "synthesis.b8:0       -           16       [5, 512, 8, 8]    float16 \n",
      "synthesis.b8:1       -           -        [5, 512, 8, 8]    float32 \n",
      "synthesis.b16.conv0  2622465     272      [5, 512, 16, 16]  float16 \n",
      "synthesis.b16.conv1  2622465     272      [5, 512, 16, 16]  float16 \n",
      "synthesis.b16.torgb  263169      -        [5, 1, 16, 16]    float16 \n",
      "synthesis.b16:0      -           16       [5, 512, 16, 16]  float16 \n",
      "synthesis.b16:1      -           -        [5, 512, 16, 16]  float32 \n",
      "synthesis.b32.conv0  2622465     1040     [5, 512, 32, 32]  float16 \n",
      "synthesis.b32.conv1  2622465     1040     [5, 512, 32, 32]  float16 \n",
      "synthesis.b32.torgb  263169      -        [5, 1, 32, 32]    float16 \n",
      "synthesis.b32:0      -           16       [5, 512, 32, 32]  float16 \n",
      "synthesis.b32:1      -           -        [5, 512, 32, 32]  float32 \n",
      "---                  ---         ---      ---               ---     \n",
      "Total                20211211    3392     -                 -       \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_images = 5\n",
    "z = torch.randn([n_images, G.z_dim], device=device)    # latent codes\n",
    "if conditional:\n",
    "    digits = torch.randint(0, G.c_dim, (n_images,), device=device)\n",
    "    c = F.one_hot(digits, G.c_dim)          \n",
    "else:\n",
    "    c = None\n",
    "misc.print_module_summary(G, [z, c])\n",
    "\n",
    "ws = G.mapping(z, c, truncation_psi=1)\n",
    "img = G.synthesis(ws, noise_mode='const', force_fp32=True)\n",
    "img = postprocess_images(img)\n",
    "plot_images(img, title='original')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classif from latent codes (Z, W, S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LatentToClass(Dataset):\n",
    "\n",
    "    def __init__(self, latent_codes, labels):\n",
    "        assert latent_codes.shape[0] == labels.shape[0], \"not same number of elements\"\n",
    "        self.latent_codes = latent_codes\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.latent_codes)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.latent_codes[idx], self.labels[idx]\n",
    "\n",
    "\n",
    "class TinyModel(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, input_dim=512, output_dim=10):\n",
    "        super().__init__()\n",
    "\n",
    "        self.linear1 = torch.nn.Linear(input_dim, 512)\n",
    "        self.linear2 = torch.nn.Linear(512, 512)\n",
    "        self.linear3 = torch.nn.Linear(512, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.linear3(x)\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        acc = (y_hat.argmax(dim=1) == y).sum() / y.shape[0]\n",
    "        self.log(\"train_loss\", loss)\n",
    "        self.log(\"train_acc\", acc)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        val_loss = F.cross_entropy(y_hat, y)\n",
    "        acc = (y_hat.argmax(dim=1) == y).sum() / y.shape[0]\n",
    "        self.log(\"val_loss\", val_loss)\n",
    "        self.log(\"val_acc\", acc)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        x, y = x.unsqueeze(0), y.unsqueeze(0)\n",
    "        y_hat = self(x)\n",
    "        acc = (y_hat.argmax(dim=1) == y).sum() / y.shape[0]\n",
    "        self.log(\"test_acc\", acc)\n",
    "        return acc\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUILD DATASETS\n",
    "\n",
    "dataset_size = 100000\n",
    "batch_size = 128\n",
    "labels = torch.randint(0, G.c_dim, (dataset_size,))\n",
    "latent_z = torch.zeros((dataset_size, G.z_dim))\n",
    "latent_w = torch.zeros((dataset_size, G.w_dim))\n",
    "latent_s = torch.zeros((dataset_size, 5632))\n",
    "\n",
    "idx = 0\n",
    "for y in DataLoader(labels, batch_size=batch_size):\n",
    "    y = y.to(device)\n",
    "    z = torch.randn([y.shape[0], G.z_dim], device=device)    # latent codes\n",
    "    c = F.one_hot(y, G.c_dim)   # one-hot class\n",
    "    ws = G.mapping(z, c)\n",
    "    img = G.synthesis(ws)\n",
    "\n",
    "    latent_z[idx:idx+z.shape[0], :] = z\n",
    "    latent_w[idx:idx+z.shape[0], :] = ws[:, 0, :]   # same w for each layer, keep only one\n",
    "    latent_s[idx:idx+z.shape[0], :] = styleSpace_dict2vec(styleSpace_values) # styleSpace_values resulting from hook\n",
    "    idx += z.shape[0]\n",
    "\n",
    "dataset_z = LatentToClass(latent_z, labels)\n",
    "dataset_w = LatentToClass(latent_w, labels)\n",
    "dataset_s = LatentToClass(latent_w, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type   | Params\n",
      "-----------------------------------\n",
      "0 | linear1 | Linear | 262 K \n",
      "1 | linear2 | Linear | 262 K \n",
      "2 | linear3 | Linear | 5.1 K \n",
      "-----------------------------------\n",
      "530 K     Trainable params\n",
      "0         Non-trainable params\n",
      "530 K     Total params\n",
      "2.122     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "810ed953eb3645e88b5cb89e74eb1851",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17d127a591824572a7861b21cf16121b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5a7d6989bd24b6183e27990893a2f03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4933530dcec443c4a6440dd989221aed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2eb818106fe4bcf87141a1d1cd9550d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08b3d0addd9b4eb3a06ee84a5ee5f6d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf5ed46b1ca948b0a26d3f1c3f9960a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa2de5004b0e4cc99743d6d391638216",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "193e8a51ff1242908b18ce5fe715fa7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "890697e110c146e7aef8fa7ad3479fdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "339c7dcb840b4b5fb8f31d86e62761c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebd0a3897ca94cf59d786553cffe1c23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/d/alecoz/miniconda3/envs/torch/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1446: UserWarning: `.test(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `test(ckpt_path='best')` to use and best model checkpoint and avoid this warning or `ckpt_path=trainer.checkpoint_callback.last_model_path` to use the last model.\n",
      "  rank_zero_warn(\n",
      "Restoring states from the checkpoint path at /d/alecoz/projects/stylegan2/code/lightning_logs/version_42/checkpoints/epoch=9-step=1570.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from checkpoint at /d/alecoz/projects/stylegan2/code/lightning_logs/version_42/checkpoints/epoch=9-step=1570.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6835f13345694b0ba092c8a1d48acc3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/d/alecoz/miniconda3/envs/torch/lib/python3.9/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 512. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\">        Test metric        </span><span style=\"font-weight: bold\">       DataLoader 0        </span>\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span><span style=\"color: #800080; text-decoration-color: #800080\">    0.10130000114440918    </span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       "\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m   0.10130000114440918   \u001b[0m\u001b[35m \u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_acc': 0.10130000114440918}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TRAIN MODEL ON Z\n",
    "\n",
    "train_set, val_set, test_set = torch.utils.data.random_split(dataset_z, [int(0.8*dataset_size), int(0.1*dataset_size), int(0.1*dataset_size)])\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=512, num_workers=4)\n",
    "val_loader = DataLoader(val_set, batch_size=512, num_workers=4)\n",
    "trainer = pl.Trainer(max_epochs=10, accelerator=\"gpu\", devices=1)\n",
    "model = TinyModel()\n",
    "\n",
    "trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=val_loader)\n",
    "trainer.test(dataloaders=test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type   | Params\n",
      "-----------------------------------\n",
      "0 | linear1 | Linear | 262 K \n",
      "1 | linear2 | Linear | 262 K \n",
      "2 | linear3 | Linear | 5.1 K \n",
      "-----------------------------------\n",
      "530 K     Trainable params\n",
      "0         Non-trainable params\n",
      "530 K     Total params\n",
      "2.122     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c80a87d23504197b30633af3020808f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67defc6f391740aca5f39627f5763838",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a793e731a6e478390882c7b4ea4ee33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "088d691c195c4e7d87e6e301e1e3f038",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0c9fe2071384e44bf88c779f1cf265e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f500e2c5f6554709a6fcfa66adbe908b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "783b754b6cd149dfa7f6f4a18fc23cbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77a940a62ad54aff863751f975df8329",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3aed111fb69646efba9cfa17429addd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d21a47be30941bd8a3f83a256491c9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4906ef7931f4b838ab0483a6c988758",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2111c89fab5f4ac3b7ea09a0254d811e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at /d/alecoz/projects/stylegan2/code/lightning_logs/version_43/checkpoints/epoch=9-step=1570.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from checkpoint at /d/alecoz/projects/stylegan2/code/lightning_logs/version_43/checkpoints/epoch=9-step=1570.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08bf3c699fe641bf9b68b3bce5d8e412",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\">        Test metric        </span><span style=\"font-weight: bold\">       DataLoader 0        </span>\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span><span style=\"color: #800080; text-decoration-color: #800080\">    0.9998999834060669     </span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       "\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m   0.9998999834060669    \u001b[0m\u001b[35m \u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_acc': 0.9998999834060669}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TRAIN MODEL ON W\n",
    "\n",
    "train_set, val_set, test_set = torch.utils.data.random_split(dataset_w, [int(0.8*dataset_size), int(0.1*dataset_size), int(0.1*dataset_size)])\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=512, num_workers=4)\n",
    "val_loader = DataLoader(val_set, batch_size=512, num_workers=4)\n",
    "trainer = pl.Trainer(max_epochs=10, accelerator=\"gpu\", devices=1)\n",
    "model = TinyModel()\n",
    "\n",
    "trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=val_loader)\n",
    "trainer.test(dataloaders=test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type   | Params\n",
      "-----------------------------------\n",
      "0 | linear1 | Linear | 262 K \n",
      "1 | linear2 | Linear | 262 K \n",
      "2 | linear3 | Linear | 5.1 K \n",
      "-----------------------------------\n",
      "530 K     Trainable params\n",
      "0         Non-trainable params\n",
      "530 K     Total params\n",
      "2.122     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d994e808c134d5a8fbe4ac03a49b866",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35bfb55c142c408ca879248d9f6c33e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26305f7f26564a3f98a033b580a501d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5983e8f35945416d8266b8897d065666",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba79039319424618b878eef05b915964",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c146822b39d4a3d94ab6719c6da87a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ee8651cfb9d44e8bbfe206f2aaa3c87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2f060c80c8a43249685ad8f3ef61643",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc528ef8eb5a4aa09da32fdb67fec501",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "462208985c08440e877d70101f8bd70c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73e0d5de00804dd8a48544431510f86c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f6d301c71d442f4981cedf5d8b7483e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at /d/alecoz/projects/stylegan2/code/lightning_logs/version_44/checkpoints/epoch=9-step=1570.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from checkpoint at /d/alecoz/projects/stylegan2/code/lightning_logs/version_44/checkpoints/epoch=9-step=1570.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3f98e038b064a41ba0c09c05ffba920",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\">        Test metric        </span><span style=\"font-weight: bold\">       DataLoader 0        </span>\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span><span style=\"color: #800080; text-decoration-color: #800080\">    0.9998000264167786     </span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       "\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m   0.9998000264167786    \u001b[0m\u001b[35m \u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_acc': 0.9998000264167786}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TRAIN MODEL ON S\n",
    "\n",
    "train_set, val_set, test_set = torch.utils.data.random_split(dataset_s, [int(0.8*dataset_size), int(0.1*dataset_size), int(0.1*dataset_size)])\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=512, num_workers=4)\n",
    "val_loader = DataLoader(val_set, batch_size=512, num_workers=4)\n",
    "trainer = pl.Trainer(max_epochs=10, accelerator=\"gpu\", devices=1)\n",
    "model = TinyModel()\n",
    "\n",
    "trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=val_loader)\n",
    "trainer.test(dataloaders=test_set)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d98911e8e1829f7f6c5e31f61dda5e143049f52824dab13c60371001bf774251"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
