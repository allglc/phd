{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a37d139-9fdc-4235-b499-c7bf8fe59cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import json\n",
    "import PIL.Image\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.utils as vutils\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "from sklearn.decomposition import PCA, IncrementalPCA\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import functools\n",
    "\n",
    "from torch_utils import misc\n",
    "import dnnlib\n",
    "import legacy\n",
    "from projector import project\n",
    "from classifiers.models import CNN_MNIST\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "path_results = Path.cwd().parent / 'results'\n",
    "# path_results = Path('/home/jovyan/results')\n",
    "# path_results = Path('/d/alecoz/projects/stylegan2-mnist-corrupted/results')\n",
    "# path_results = Path('/home/jovyan/results_temp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70975fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_output_to_classifier_input(images):\n",
    "    \n",
    "    lo, hi = [-1, 1] # generator scale\n",
    "    images = images.cpu()\n",
    "    images = (images - lo) * (255 / (hi - lo)) # classifier scale\n",
    "    images = np.rint(images).clip(0, 255)\n",
    "    images = images[:, :, 2:30, 2:30] # remove padding\n",
    "    images = images.to(device)\n",
    "\n",
    "    return images\n",
    "\n",
    "def postprocess_images(img):\n",
    "    # from generate.py\n",
    "    if img.dim() == 4: # B x C x H x W\n",
    "        img = (img.permute(0, 2, 3, 1) * 127.5 + 128).clamp(0, 255).to(torch.uint8)\n",
    "    elif img.dim() == 3:  # C x H x W\n",
    "        img = (img.permute(1, 2, 0) * 127.5 + 128).clamp(0, 255).to(torch.uint8)\n",
    "    return img\n",
    "\n",
    "\n",
    "def generate_from_z(z):\n",
    "    for i in np.arange(0, z.shape[0], batch_size):\n",
    "        img = G(z[i:i+batch_size], c=None, noise_mode='const', force_fp32=True)\n",
    "        if i == 0: \n",
    "            imgs = img\n",
    "        else:\n",
    "            imgs = torch.cat((imgs, img))\n",
    "    return imgs\n",
    "\n",
    "\n",
    "def plot_random_images(imgs):\n",
    "    # from generate.py: img = (img.permute(0, 2, 3, 1) * 127.5 + 128).clamp(0, 255).to(torch.uint8)[0].cpu().numpy()\n",
    "    # imgs = (imgs * 127.5 + 128).clamp(0, 255).to(torch.uint8)\n",
    "    imgs = postprocess_images(imgs)\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(vutils.make_grid(imgs[torch.randint(0, imgs.shape[0], (100,))].cpu(), pad_value=255, nrow=10).permute(1,2,0))\n",
    "\n",
    "    \n",
    "def truncate(x, x_avg, psi):\n",
    "    # psi=0 means we get average value, \n",
    "    # psi=1 we get original value, \n",
    "    # 0<psi<1 we get interpolation between mean and original\n",
    "    return x_avg.lerp(x, psi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d211d4c-994e-48a8-a5e7-dbaf3da4f5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_model = Path(\"/home/jovyan/results/stylegan2-training-runs/00014-mnist_stylegan2-cond-auto1-dim64\")\n",
    "# path_model = Path(\"/home/jovyan/results/stylegan2-training-runs/00015-mnist_stylegan2-auto1-dim64\")\n",
    "# path_model = Path(\"/home/jovyan/results/stylegan2-training-runs/00016-mnist_stylegan2-cond-auto2-dim64_FAILED\")\n",
    "\n",
    "# path_model = path_results / 'stylegan2-training-runs' / '00010-mnist_stylegan2-auto2-dim512'\n",
    "# path_model = path_results / 'stylegan2-training-runs' / '00014-mnist_stylegan2-cond-auto1-dim64'\n",
    "# path_model = path_results / 'stylegan2-training-runs' / '00015-mnist_stylegan2-auto1-dim64'\n",
    "# path_model = path_results / 'stylegan2-training-runs' / '00016-mnist_stylegan2-cond-auto2-dim64_FAILED'\n",
    "# path_model = path_results / 'stylegan2-training-runs' / '00023-mnist_stylegan2_noise_blur-cond-auto2-dim512'\n",
    "# path_model = path_results / 'stylegan2-training-runs' / '00024-mnist_stylegan2_noise_blur-auto2'\n",
    "# path_model = path_results / 'stylegan2-training-runs' / '00028-mnist_stylegan2_noise-cond-auto1-dim64'\n",
    "# path_model = path_results / 'stylegan2-training-runs' / '00029-mnist_stylegan2_noise-auto2-dim64'\n",
    "\n",
    "\n",
    "# path_model = 'https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/afhqcat.pkl'\n",
    "# path_model = 'https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/afhqdog.pkl'\n",
    "# path_model = 'https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/afhqwild.pkl'\n",
    "# path_model = 'https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/brecahad.pkl'\n",
    "# path_model = 'https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/cifar10.pkl'\n",
    "# path_model = 'https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/ffhq.pkl'\n",
    "# path_model = 'https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/metfaces.pkl'\n",
    "\n",
    "path_model = path_results / 'stylegan2-training-runs' / '00015-mnist_stylegan2_blur_noise-cond-auto4'\n",
    "path_model = path_results / 'stylegan2-training-runs' / '00016-mnist_stylegan2_blur_noise_maxSeverity3_proba50-cond-auto4'\n",
    "\n",
    "# find best model in folder\n",
    "if not str(path_model).endswith('pkl'):\n",
    "    with open(path_model / 'metric-fid50k_full.jsonl', 'r') as json_file:\n",
    "        json_list = list(json_file)\n",
    "\n",
    "    best_fid = 1e6\n",
    "    for json_str in json_list:\n",
    "        json_line = json.loads(json_str)\n",
    "        if json_line['results']['fid50k_full'] < best_fid:\n",
    "            best_fid = json_line['results']['fid50k_full']\n",
    "            best_model = json_line['snapshot_pkl']\n",
    "    print('Best FID: {:.2f} ; best model : {}'.format(best_fid, best_model))\n",
    "\n",
    "    # remove all models except best\n",
    "    models_to_delete = [m for m in path_model.glob('*.pkl') if m.name != best_model]\n",
    "    for m in models_to_delete:\n",
    "        m.unlink(missing_ok=True)\n",
    "\n",
    "    path_model = path_model / best_model\n",
    "    with open(path_model, 'rb') as f:\n",
    "        G = pickle.load(f)['G_ema'].cuda()  # torch.nn.Module\n",
    "\n",
    "else:\n",
    "    with dnnlib.util.open_url(path_model) as f:\n",
    "        G = legacy.load_network_pkl(f)['G_ema'].to(device)\n",
    "\n",
    "if device == 'cpu': G.forward = functools.partial(G.forward, force_fp32=True)\n",
    "\n",
    "conditional = G.c_dim > 0\n",
    "\n",
    "# registor hooks to save intermediate values\n",
    "intermediate_images_torgb = {}\n",
    "def get_torgb(name):\n",
    "    def hook(model, input, output):\n",
    "        intermediate_images_torgb[name] = output.detach()\n",
    "    return hook\n",
    "intermediate_images_block = {}\n",
    "def get_block_img(name):\n",
    "    def hook(model, input, output):\n",
    "        intermediate_images_block[name] = output[1].detach()\n",
    "    return hook\n",
    "for res in G.synthesis.block_resolutions:\n",
    "    block = getattr(G.synthesis, f'b{res}')\n",
    "    block.torgb.register_forward_hook(get_torgb(res))\n",
    "    block.register_forward_hook(get_block_img(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558c917e-3b2e-4525-9d48-c656528fefe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_images = 2\n",
    "z = torch.randn([n_images, G.z_dim], device=device)    # latent codes\n",
    "if conditional:\n",
    "    digits = torch.randint(0, G.c_dim, (n_images,))\n",
    "    c = F.one_hot(digits, G.c_dim, device=device)          \n",
    "else:\n",
    "    c = None\n",
    "img = G(z, c)                           # NCHW, float32, dynamic range [-1, +1]\n",
    "\n",
    "ws = G.mapping(z, c, truncation_psi=0.5, truncation_cutoff=8)\n",
    "img = G.synthesis(ws, noise_mode='const', force_fp32=True)\n",
    "img = postprocess_images(img)\n",
    "\n",
    "# misc.print_module_summary(G, [z, c])\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(vutils.make_grid(img.permute(0, 3, 1, 2)).permute(1,2,0))\n",
    "plt.axis('off')\n",
    "plt.grid(False)\n",
    "plt.title('random images')\n",
    "\n",
    "\n",
    "z_avg = torch.zeros((1, G.z_dim), device=device)\n",
    "img_avg = G(z_avg, c, noise_mode='const')\n",
    "img_avg = postprocess_images(img_avg)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(img_avg.squeeze(0).cpu())\n",
    "plt.axis('off')\n",
    "plt.grid(False)\n",
    "plt.title('average image')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e72a61d-51ec-40da-ac98-579f35f55dff",
   "metadata": {},
   "source": [
    "## Show intermediate layers outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb3dc6f-1114-4a8b-b7ed-54a2289bef13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test having a constant input 4x4xdim \"image\"\n",
    "# G.synthesis.b4.const.data =  torch.ones_like(G.synthesis.b4.const.data)\n",
    "\n",
    "up = torch.nn.Upsample(size=[G.img_resolution, G.img_resolution])\n",
    "\n",
    "z = torch.randn([1, G.z_dim], device=device)    # latent codes\n",
    "_ = G(z, c, noise_mode='const')\n",
    "\n",
    "intermediate_images_torgb = {k: up(v).cpu().squeeze() for k, v in intermediate_images_torgb.items()}\n",
    "fig, axs = plt.subplots(1, len(intermediate_images_torgb), figsize=(20, 3))\n",
    "fig.suptitle('torgb outputs')\n",
    "for ax, (k, v) in zip(axs.ravel(), intermediate_images_torgb.items()):\n",
    "    v = postprocess_images(v).squeeze(0)\n",
    "    ax.imshow(v)\n",
    "    ax.axis('off')\n",
    "    ax.set_title(f'{k}x{k}')\n",
    "\n",
    "intermediate_images_block = {k: up(v).cpu().squeeze() for k, v in intermediate_images_block.items()}\n",
    "fig, axs = plt.subplots(1, len(intermediate_images_block), figsize=(20, 3))\n",
    "fig.suptitle('block outputs')\n",
    "for ax, (k, v) in zip(axs.ravel(), intermediate_images_block.items()):\n",
    "    v = postprocess_images(v).squeeze(0)\n",
    "    ax.imshow(v)\n",
    "    ax.axis('off')\n",
    "    ax.set_title(f'{k}x{k}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16eb3940",
   "metadata": {},
   "source": [
    "# Sample latent codes and generate images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c298e6f5-bb24-497f-aa7b-36863f0186f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 10000\n",
    "# Sample gaussian noise and classes\n",
    "zs = torch.randn([n_samples, G.z_dim], device='cuda')\n",
    "if conditional:\n",
    "    digits = torch.randint(0, 10, (n_samples,), device='cuda')\n",
    "    c = F.one_hot(digits, 10)\n",
    "else:\n",
    "    c = None\n",
    "\n",
    "# Get latent code in W\n",
    "ws = G.mapping(zs, c, truncation_psi=0.5, truncation_cutoff=8)\n",
    "\n",
    "# Generate images\n",
    "batch_size = 1000\n",
    "# imgs = []\n",
    "for i in np.arange(0, n_samples, batch_size):\n",
    "    imgs_new = G.synthesis(ws[i:i+batch_size], noise_mode='const', force_fp32=True)\n",
    "    if i == 0: \n",
    "        imgs = imgs_new\n",
    "    else:\n",
    "        imgs = torch.cat((imgs, imgs_new))\n",
    "\n",
    "ws = ws[:, 0, :] # remove repeated dimensions\n",
    "# ws = ws.cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22c070b-f76a-4e56-a129-4b7bf3c2c7a7",
   "metadata": {},
   "source": [
    "## PCA in W space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66610f4-7a3a-46b5-9f5d-a68d37e7817a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=G.z_dim)\n",
    "pca.fit(ws.cpu().numpy())\n",
    "# stdev = np.dot(pca.components_, ws.T).std(axis=1) # why not same as pca.explained_variance_ ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170a0604-30d9-4880-9d03-80122d383afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_images = 1\n",
    "z = torch.randn([n_images, G.z_dim]).cuda()    # latent codes\n",
    "if conditional:\n",
    "    digits = torch.tensor([9])#torch.randint(0, 10, (n_images,))\n",
    "    c = F.one_hot(digits, 10).cuda()          # class labels (not used in this example)\n",
    "else:\n",
    "    c = None\n",
    "\n",
    "idx_direction = 0\n",
    "direction = pca.components_[idx_direction, :]\n",
    "direction = torch.tensor(direction).cuda()\n",
    "k = 10*np.array([-2, -1, -0.5, 0, 0.5, 1, 2])\n",
    "\n",
    "images = []\n",
    "for i in range(7):\n",
    "    z_new = z + k[i]*direction\n",
    "    img = G(z_new, c)\n",
    "    img = postprocess_images(img).cpu()\n",
    "    images.append(img)\n",
    "    \n",
    "images = torch.cat(images, 0)\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(vutils.make_grid(images, pad_value=255, nrow=7).permute(1,2,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a016e83",
   "metadata": {},
   "source": [
    "## Load and test classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0d6c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict digits\n",
    "classifier_digits = CNN_MNIST(output_dim=10).to(device)\n",
    "classifier_digits.load_state_dict(torch.load(path_results / 'classifiers' / 'CNN_MNIST_weights_20220209_1612.pth')) # DeepLab\n",
    "# classifier_digits.load_state_dict(torch.load(path_results / 'classifiers' / 'CNN_MNIST_weights_20220210_1601.pth')) # Confiance\n",
    "\n",
    "# predict noise\n",
    "classifier_noise = CNN_MNIST(output_dim=6).to(device)\n",
    "classifier_noise.load_state_dict(torch.load(path_results / 'classifiers' / 'CNN_MNIST_noise_weights_20220210_1728.pth')) # Confiance\n",
    "\n",
    "\n",
    "x = generator_output_to_classifier_input(imgs)\n",
    "digit_pred = classifier_digits(x).argmax(dim=1).cpu()\n",
    "noise_pred = classifier_noise(x).argmax(dim=1).cpu()\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "for i in range(10):\n",
    "    idx = np.random.randint(0, len(x))\n",
    "    plt.subplot(1, 10, i+1)\n",
    "    plt.imshow(x[idx].cpu().squeeze(), cmap='gray')\n",
    "    plt.title(f'digit: {digit_pred[idx].numpy()} \\n noise: {noise_pred[idx].numpy()}')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd76c82",
   "metadata": {},
   "source": [
    "## t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f47670",
   "metadata": {},
   "outputs": [],
   "source": [
    "zs_embedded = TSNE(n_components=2, learning_rate='auto', init='random').fit_transform(zs.cpu().numpy())\n",
    "ws_embedded = TSNE(n_components=2, learning_rate='auto', init='random').fit_transform(ws.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6d0b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z space\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "fig.suptitle('t-SNE in Z space')\n",
    "scatter1 = axs[0].scatter(zs_embedded[:, 0], zs_embedded[:, 1], c=noise_pred, alpha=0.2, cmap='jet')\n",
    "legend1 = axs[0].legend(*scatter1.legend_elements(), loc=\"lower left\", title=\"Noise\")\n",
    "for lh in legend1.legendHandles: \n",
    "    lh.set_alpha(1)\n",
    "axs[0].add_artist(legend1)\n",
    "axs[0].axis('off')\n",
    "\n",
    "scatter2 = axs[1].scatter(zs_embedded[:, 0], zs_embedded[:, 1], c=digit_pred, alpha=0.2, cmap='jet')\n",
    "legend2 = axs[1].legend(*scatter2.legend_elements(),\n",
    "                    loc=\"lower left\", title=\"Digits\")\n",
    "for lh in legend2.legendHandles: \n",
    "    lh.set_alpha(1)\n",
    "axs[1].add_artist(legend2)\n",
    "axs[1].axis('off')\n",
    "\n",
    "\n",
    "# W space\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "fig.suptitle('t-SNE in W space')\n",
    "scatter1 = axs[0].scatter(ws_embedded[:, 0], ws_embedded[:, 1], c=noise_pred, alpha=0.2, cmap='jet')\n",
    "legend1 = axs[0].legend(*scatter1.legend_elements(), loc=\"lower left\", title=\"Noise\")\n",
    "for lh in legend1.legendHandles: \n",
    "    lh.set_alpha(1)\n",
    "axs[0].add_artist(legend1)\n",
    "axs[0].axis('off')\n",
    "\n",
    "scatter2 = axs[1].scatter(ws_embedded[:, 0], ws_embedded[:, 1], c=digit_pred, alpha=0.2, cmap='jet')\n",
    "legend2 = axs[1].legend(*scatter2.legend_elements(),\n",
    "                    loc=\"lower left\", title=\"Digits\")\n",
    "for lh in legend2.legendHandles: \n",
    "    lh.set_alpha(1)\n",
    "axs[1].add_artist(legend2)\n",
    "axs[1].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33256ab1-bf07-4e4c-9dca-8d49276a8a26",
   "metadata": {},
   "source": [
    "## Histograms Z and W space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c86f1e8-3d30-4120-b529-234310426eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 10, figsize=(15, 8))\n",
    "for i in range(10):\n",
    "    idx = np.random.randint(0, G.z_dim)\n",
    "    axs[0,i].hist(zs[:, idx].cpu().numpy(), bins=100)\n",
    "    axs[0,i].set(yticklabels=[])  # remove the tick labels\n",
    "    axs[0,i].tick_params(left=False)  # remove the ticks\n",
    "    axs[0,i].set_title(f'z_{idx}')\n",
    "    axs[1,i].hist(ws[:, idx].cpu().numpy(), bins=100)\n",
    "    axs[1,i].set(yticklabels=[])  # remove the tick labels\n",
    "    axs[1,i].tick_params(left=False)  # remove the ticks\n",
    "    axs[1,i].set_title(f'w_{idx}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce2581e-9c81-4ee3-a113-801bdf8522fb",
   "metadata": {},
   "source": [
    "## Find noise direction in Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2d892c-d85f-48b7-b559-7a3385171d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load noise classifier\n",
    "classifier_noise = CNN_MNIST(output_dim=6).to(device)\n",
    "classifier_noise.load_state_dict(torch.load(path_results / 'classifiers' / 'CNN_MNIST_noise_weights_20220210_1728.pth')) # Confiance\n",
    "\n",
    "x = generator_output_to_classifier_input(imgs)\n",
    "predictions = classifier_noise(x).detach().cpu()\n",
    "y_pred = np.argmax(predictions, 1)\n",
    "\n",
    "# keep latent codes of images with noise = 1 and 5\n",
    "z_noise_low = zs[y_pred == 1].squeeze()\n",
    "z_noise_high = zs[y_pred == 5].squeeze()\n",
    "\n",
    "avg_z_noise_low = torch.mean(z_noise_low, axis=0)\n",
    "avg_z_noise_high = torch.mean(z_noise_high, axis=0)\n",
    "\n",
    "# average of latent codes for noisy - average of latent codes for uncorrupted\n",
    "noise_direction_z = avg_z_noise_high - avg_z_noise_low\n",
    "\n",
    "\n",
    "# Show examples\n",
    "nb_interp = 9\n",
    "images = []\n",
    "for i in range(5):\n",
    "    z = torch.randn(1, G.z_dim, device=device)\n",
    "    if conditional:\n",
    "        digits = torch.tensor([8])#torch.randint(0, 10, (n_images,))\n",
    "        c = F.one_hot(digits, 10).cuda()          # class labels (not used in this example)\n",
    "    else:\n",
    "        c = None\n",
    "\n",
    "    for alpha in np.linspace(-1, 1, num=nb_interp):\n",
    "        z_new = z + alpha*noise_direction_z\n",
    "        # z_new = z_new / z_new.norm() * z.norm()\n",
    "        img = G(z_new, c)\n",
    "        img = postprocess_images(img).cpu()\n",
    "        images.append(img)\n",
    "\n",
    "images = torch.cat(images, 0)\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(vutils.make_grid(images, pad_value=255, nrow=nb_interp).permute(1,2,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e5a87f-a358-417d-b50f-784aff53ad16",
   "metadata": {},
   "source": [
    "## Find noise direction in W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54c8c37-3bf1-418c-909e-f3031ddac819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load noise classifier\n",
    "classifier_noise = CNN_MNIST(output_dim=6).to(device)\n",
    "classifier_noise.load_state_dict(torch.load(path_results / 'classifiers' / 'CNN_MNIST_noise_weights_20220210_1728.pth')) # Confiance\n",
    "\n",
    "x = generator_output_to_classifier_input(imgs)\n",
    "predictions = classifier_noise(x).detach().cpu()\n",
    "y_pred = np.argmax(predictions, 1)\n",
    "\n",
    "# keep latent codes of images with noise = 1 and 5\n",
    "w_noise_low = ws[y_pred == 1].squeeze()\n",
    "w_noise_high = ws[y_pred == 5].squeeze()\n",
    "\n",
    "avg_w_noise_low = torch.mean(w_noise_low, axis=0)\n",
    "avg_w_noise_high = torch.mean(w_noise_high, axis=0)\n",
    "\n",
    "# average of latent codes for noisy - average of latent codes for uncorrupted\n",
    "noise_direction_w = (avg_w_noise_high - avg_w_noise_low).cuda()\n",
    "\n",
    "# Show examples\n",
    "nb_interp = 9\n",
    "images = []\n",
    "for i in range(5):\n",
    "    z = torch.randn(1, G.z_dim, device=device)\n",
    "    if conditional:\n",
    "        digits = torch.tensor([9])#torch.randint(0, 10, (n_images,))\n",
    "        c = F.one_hot(digits, 10).cuda()          # class labels (not used in this example)\n",
    "    else:\n",
    "        c = None\n",
    "    w = G.mapping(z, c, truncation_psi=0.5, truncation_cutoff=8)\n",
    "\n",
    "    for alpha in np.linspace(-1, 1, num=nb_interp):\n",
    "        w_new = w + alpha*noise_direction_w\n",
    "        # w_new = w_new / w_new.norm() * w.norm()\n",
    "        img = G.synthesis(w_new, noise_mode='const', force_fp32=True)\n",
    "        img = postprocess_images(img).cpu()\n",
    "        images.append(img)\n",
    "\n",
    "images = torch.cat(images, 0)\n",
    "# vutils.make_grid(images).permute(1,2,0)\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(vutils.make_grid(images, pad_value=255, nrow=nb_interp).permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4264368d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 10, figsize=(15, 8))\n",
    "fig.suptitle('histograms for low noise samples (blue) and high noise samples (red)')\n",
    "for i in range(10):\n",
    "    idx = np.random.randint(0, G.z_dim)\n",
    "    axs[0,i].hist(z_noise_low[:, idx].cpu().numpy(), bins=100, density=True, color='tab:blue', alpha=0.5)\n",
    "    axs[0,i].hist(z_noise_high[:, idx].cpu().numpy(), bins=100, density=True, color='tab:red', alpha=0.5)\n",
    "    axs[0,i].set(yticklabels=[])  # remove the tick labels\n",
    "    axs[0,i].tick_params(left=False)  # remove the ticks\n",
    "    axs[0,i].set_title(f'z_{idx}')\n",
    "    axs[1,i].hist(w_noise_low[:, idx].cpu().numpy(), bins=100, density=True, color='tab:blue', alpha=0.5)\n",
    "    axs[1,i].hist(w_noise_high[:, idx].cpu().numpy(), bins=100, density=True, color='tab:red', alpha=0.5)\n",
    "    axs[1,i].set(yticklabels=[])  # remove the tick labels\n",
    "    axs[1,i].tick_params(left=False)  # remove the ticks\n",
    "    axs[1,i].set_title(f'w_{idx}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c14bed-8a34-4e55-b924-4a94281a5d7e",
   "metadata": {},
   "source": [
    "## Domain with low noise samples\n",
    "https://fr.m.wikipedia.org/wiki/Calcul_de_l%27enveloppe_convexe\n",
    "\n",
    "https://en.m.wikipedia.org/wiki/Extreme_point\n",
    "\n",
    "https://en.m.wikipedia.org/wiki/Convex_combination\n",
    "\n",
    "Convex combination of samples only results of samples very close to the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bcf36f-1c68-48d5-865d-79f5a4a9de6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x0 = np.array([[1, 1]])\n",
    "# x1 = np.array([[2, 5]])\n",
    "# x2 = np.array([[3, 4]])\n",
    "# x3 = np.array([[2, 3]])\n",
    "\n",
    "\n",
    "# X = np.concatenate((x0, x1, x2, x3))\n",
    "\n",
    "# alpha = np.random.uniform(size=(100, len(X)))\n",
    "# alpha = alpha / np.sum(alpha, axis=1, keepdims=1)\n",
    "\n",
    "# x_cc = np.expand_dims(alpha[:, 0], 1)*x0 + np.expand_dims(alpha[:, 1], 1)*x1 + np.expand_dims(alpha[:, 2], 1)*x2 + np.expand_dims(alpha[:, 3], 1)*x3\n",
    "\n",
    "# plt.figure()\n",
    "# plt.scatter(X[:, 0], X[:, 1])\n",
    "# plt.scatter(x_cc[:, 0], x_cc[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8e72c9-575e-4c2a-881d-5d36f1c045f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep latent codes of images with noise = 1\n",
    "z_noise_low = zs[noise_pred == 1].squeeze().to(device)\n",
    "\n",
    "images = generate_from_z(z_noise_low)\n",
    "plot_random_images(images)\n",
    "\n",
    "low_noise_distrib = torch.distributions.normal.Normal(z_noise_low.mean(axis=0), z_noise_low.std(axis=0))\n",
    "z_low_noise_samples = low_noise_distrib.sample((1000,))\n",
    "z_low_noise_samples = truncate(z_low_noise_samples, z_noise_low.mean(axis=0), 0.5)\n",
    "images = generate_from_z(z_low_noise_samples)\n",
    "plot_random_images(images)\n",
    "\n",
    "x = generator_output_to_classifier_input(images)\n",
    "predictions = classifier_noise(x).detach().cpu()\n",
    "y_pred = np.argmax(predictions, 1)\n",
    "\n",
    "plt.figure()\n",
    "sns.countplot(x=y_pred.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b04d94-d608-4e0a-aa0b-47c006c2cadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_noise_high = zs[noise_pred == 5].squeeze().to(device)\n",
    "\n",
    "images = generate_from_z(z_noise_high)\n",
    "plot_random_images(images)\n",
    "\n",
    "\n",
    "high_noise_distrib = torch.distributions.normal.Normal(z_noise_high.mean(axis=0), z_noise_high.std(axis=0))\n",
    "z_high_noise_samples = high_noise_distrib.sample((1000,))\n",
    "z_high_noise_samples = truncate(z_high_noise_samples, z_noise_high.mean(axis=0), 1)\n",
    "images = generate_from_z(z_high_noise_samples)\n",
    "plot_random_images(images)\n",
    "\n",
    "x = generator_output_to_classifier_input(images)\n",
    "predictions = classifier_noise(x).detach().cpu()\n",
    "y_pred = np.argmax(predictions, 1)\n",
    "\n",
    "plt.figure()\n",
    "sns.countplot(x=y_pred.numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab660aa-6696-451b-821a-a50820cc7704",
   "metadata": {},
   "source": [
    "## Truncation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c7eec6-9272-4b58-ab62-0bc3bcc4c9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_images = 5\n",
    "z = torch.randn([n_images, G.z_dim], device=device)    # latent codes\n",
    "if conditional:\n",
    "    digits = torch.randint(0, G.c_dim, (n_images,))\n",
    "    c = F.one_hot(digits, G.c_dim, device=device)          \n",
    "else:\n",
    "    c = None\n",
    "\n",
    "ws = G.mapping(z, c, truncation_psi=1, truncation_cutoff=8)[:, 0, :]\n",
    "w_avg = G.mapping.w_avg\n",
    "\n",
    "# Show examples\n",
    "psi_max = 2\n",
    "nb_interp = 9\n",
    "images = []\n",
    "for i in range(n_images):\n",
    "    for psi in np.linspace(-psi_max, psi_max, num=nb_interp):\n",
    "        w_new = w_avg + psi*(ws[i, :]-w_avg)\n",
    "        w_new = w_new.repeat(1, G.synthesis.num_ws, 1)\n",
    "        img = G.synthesis(w_new, noise_mode='const', force_fp32=True)\n",
    "        img = postprocess_images(img).cpu()\n",
    "        images.append(img)\n",
    "\n",
    "images = torch.cat(images, 0)\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(vutils.make_grid(images.permute((0, 3, 1, 2)), pad_value=255, nrow=nb_interp).permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b805ae69-3cd3-47e8-ba20-776b02bbc71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "psi_max = 10\n",
    "nb_interp = 30\n",
    "images = []\n",
    "idx = torch.randint(len(ws), (1000,))\n",
    "w = ws[idx, :]\n",
    "first = True\n",
    "for psi in np.linspace(-psi_max, psi_max, num=nb_interp):\n",
    "    w_new_temp = w_avg + psi*(w-w_avg)\n",
    "    img = G.synthesis(w_new_temp.unsqueeze(1).repeat(1, 8, 1), noise_mode='const', force_fp32=True)\n",
    "    # img = postprocess_image(img).cpu()\n",
    "    if first: \n",
    "        images = img\n",
    "        w_new = w_new_temp\n",
    "        first = False\n",
    "    else:\n",
    "        images = torch.cat((images, img))\n",
    "        w_new = torch.cat((w_new, w_new_temp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5269053-2d1b-42dc-b828-a70ac258ee34",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = generator_output_to_classifier_input(images)\n",
    "predictions = classifier_digits(x).detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94dc301-da26-4416-9694-f193e00e6c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_from_center = torch.cdist(w_new, w_avg.unsqueeze(0)).squeeze().cpu()\n",
    "confidence = F.softmax(predictions, dim=1).max(dim=1).values.cpu()\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(dist_from_center, confidence, alpha=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55973049-790c-4ec8-8c44-aa307dc7f587",
   "metadata": {},
   "source": [
    "## Convex combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29163a1-c0f9-4d8d-8f5a-f362e5d144f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convex_combination(alpha, X):\n",
    "    \n",
    "    assert alpha.shape[0] == X.shape[0]\n",
    "    x_new = 0\n",
    "    for i in range(X.shape[0]):\n",
    "        x_new += alpha[i] * X[i, :]\n",
    "        \n",
    "    return x_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18c001d-8ad1-4082-9525-cdcdf05c2897",
   "metadata": {},
   "outputs": [],
   "source": [
    "corner_cases = np.random.randint(0, 10, (100, 2))\n",
    "\n",
    "x_cc = np.zeros((100, 2))\n",
    "for i in range(100):\n",
    "    alpha = np.random.uniform(size=(len(corner_cases)))\n",
    "    alpha = alpha / np.sum(alpha)\n",
    "    # alpha = 0.1 * alpha\n",
    "    x_cc[i, :] = convex_combination(alpha, corner_cases)\n",
    "    \n",
    "plt.figure()\n",
    "plt.scatter(x_cc[:, 0], x_cc[:, 1])\n",
    "plt.scatter(corner_cases[:, 0], corner_cases[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cca5167-72dd-465c-9dd9-aa30a5176b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.uniform(size=(50, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b500ffc5-4490-46ab-b37e-2bc22654f07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import ConvexHull\n",
    "hull = ConvexHull(np.random.uniform(size=(100, 5)))\n",
    "hull.vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ff083e-f6c9-4c02-8dce-e0c6cc6e5e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_img = 100\n",
    "corner_cases = z_noise_low.cpu()\n",
    "z_new = np.zeros((nb_img, G.z_dim))\n",
    "for i in range(nb_img):\n",
    "    alpha = np.random.uniform(size=(len(corner_cases)))\n",
    "    alpha = alpha / np.sum(alpha)\n",
    "    alpha = alpha\n",
    "    z_new[i, :] = convex_combination(alpha, corner_cases)\n",
    "z_new = torch.from_numpy(z_new).to(device)\n",
    "\n",
    "# Generate images\n",
    "images = generate_from_z(z_new)\n",
    "plot_random_images(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4fa484-a397-42fa-b50b-ebd8c93f2c6d",
   "metadata": {},
   "source": [
    "## Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b804b9-f173-4ea1-98b5-f66770cb699b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_projection(\n",
    "    network_pkl: str,\n",
    "    target_fname: str,\n",
    "    outdir: str,\n",
    "    save_video: bool,\n",
    "    seed: int,\n",
    "    num_steps: int\n",
    "):\n",
    "    \"\"\"Project given image to the latent space of pretrained network pickle.\n",
    "\n",
    "    Examples:\n",
    "\n",
    "    \\b\n",
    "    python projector.py --outdir=out --target=~/mytargetimg.png \\\\\n",
    "        --network=https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/ffhq.pkl\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    # Load networks.\n",
    "    print('Loading networks from \"%s\"...' % network_pkl)\n",
    "    device = torch.device('cuda')\n",
    "    with dnnlib.util.open_url(network_pkl) as fp:\n",
    "        G = legacy.load_network_pkl(fp)['G_ema'].requires_grad_(False).to(device) # type: ignore\n",
    "\n",
    "    # Load target image.\n",
    "    target_pil = PIL.Image.open(target_fname).convert('RGB')\n",
    "    w, h = target_pil.size\n",
    "    s = min(w, h)\n",
    "    target_pil = target_pil.crop(((w - s) // 2, (h - s) // 2, (w + s) // 2, (h + s) // 2))\n",
    "    target_pil = target_pil.resize((G.img_resolution, G.img_resolution), PIL.Image.LANCZOS)\n",
    "    target_uint8 = np.array(target_pil, dtype=np.uint8)\n",
    "\n",
    "    # Optimize projection.\n",
    "    start_time = perf_counter()\n",
    "    projected_w_steps = project(\n",
    "        G,\n",
    "        target=torch.tensor(target_uint8.transpose([2, 0, 1]), device=device), # pylint: disable=not-callable\n",
    "        num_steps=num_steps,\n",
    "        device=device,\n",
    "        verbose=True\n",
    "    )\n",
    "    print (f'Elapsed: {(perf_counter()-start_time):.1f} s')\n",
    "\n",
    "    # Render debug output: optional video and projected image and W vector.\n",
    "    os.makedirs(outdir, exist_ok=True)\n",
    "    if save_video:\n",
    "        video = imageio.get_writer(f'{outdir}/proj.mp4', mode='I', fps=10, codec='libx264', bitrate='16M')\n",
    "        print (f'Saving optimization progress video \"{outdir}/proj.mp4\"')\n",
    "        for projected_w in projected_w_steps:\n",
    "            synth_image = G.synthesis(projected_w.unsqueeze(0), noise_mode='const')\n",
    "            synth_image = (synth_image + 1) * (255/2)\n",
    "            synth_image = synth_image.permute(0, 2, 3, 1).clamp(0, 255).to(torch.uint8)[0].cpu().numpy()\n",
    "            video.append_data(np.concatenate([target_uint8, synth_image], axis=1))\n",
    "        video.close()\n",
    "\n",
    "    # Save final projected frame and W vector.\n",
    "    target_pil.save(f'{outdir}/target.png')\n",
    "    projected_w = projected_w_steps[-1]\n",
    "    synth_image = G.synthesis(projected_w.unsqueeze(0), noise_mode='const')\n",
    "    synth_image = (synth_image + 1) * (255/2)\n",
    "    synth_image = synth_image.permute(0, 2, 3, 1).clamp(0, 255).to(torch.uint8)[0].cpu().numpy()\n",
    "    PIL.Image.fromarray(synth_image, 'RGB').save(f'{outdir}/proj.png')\n",
    "    np.savez(f'{outdir}/projected_w.npz', w=projected_w.unsqueeze(0).cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16303d92-17be-4ee8-a90f-b66cb9d3243d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load networks.\n",
    "# network_pkl = 'https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/ffhq.pkl'\n",
    "# print('Loading networks from \"%s\"...' % network_pkl)\n",
    "# device = torch.device('cuda')\n",
    "# with dnnlib.util.open_url(network_pkl) as fp:\n",
    "#     # G = legacy.load_network_pkl(fp)['G_ema'].requires_grad_(False).to(device) # type: ignore\n",
    "#     G = pickle.load(fp)['G_ema'].requires_grad_(False).to(device) # type: ignore\n",
    "        \n",
    "        \n",
    "#         # Load target image.\n",
    "# target_pil = PIL.Image.open('face.png').convert('RGB')\n",
    "# w, h = target_pil.size\n",
    "# s = min(w, h)\n",
    "# target_pil = target_pil.crop(((w - s) // 2, (h - s) // 2, (w + s) // 2, (h + s) // 2))\n",
    "# target_pil = target_pil.resize((G.img_resolution, G.img_resolution), PIL.Image.LANCZOS)\n",
    "# target_uint8 = np.array(target_pil, dtype=np.uint8)\n",
    "\n",
    "# # Optimize projection.\n",
    "# # start_time = perf_counter()\n",
    "# projected_w_steps = project(\n",
    "#     G,\n",
    "#     target=torch.tensor(target_uint8.transpose([2, 0, 1]), device=device), # pylint: disable=not-callable\n",
    "#     # num_steps=num_steps,\n",
    "#     device=device,\n",
    "#     verbose=True\n",
    "# )\n",
    "# # print (f'Elapsed: {(perf_counter()-start_time):.1f} s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d1fbb5-4f1b-49b3-a135-8e74f18ab9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = 'https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/metrics/vgg16.pt'\n",
    "# with dnnlib.util.open_url(url) as f:\n",
    "#     print('bla')\n",
    "#     print(f)\n",
    "#     # vgg16 = torch.jit.load(f).eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86669916-3c92-4dfa-9f7e-1feac7e51508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dnnlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86e57b3-8fd4-4806-8f5d-7f6032dcf244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with dnnlib.util.open_url(url) as f:\n",
    "#     vgg16 = torch.jit.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11667777-a51d-410a-bfdc-6fbc1b54c293",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a548c4-29fd-4178-9488-9132ef2da06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16.eval().to(torch.device('cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebb96e7-ec57-40a5-b870-3365dc93c681",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2feebe-2872-4055-8a42-e79c803ef906",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "be29417f512f17686a4dbdba59af0eb1139b62de73b819669badaf0c77e80723"
  },
  "kernelspec": {
   "display_name": "ALC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
