{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "import torch\n",
    "from datetime import datetime\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "from models import Generator_28, Discriminator_28\n",
    "from utils import get_noise, get_gradient_penalty, show_tensor_images, compute_fid\n",
    "from imagenet_c import corrupt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "architecture = 'DCGAN' # DCGAN or WGAN-GP\n",
    "conditional = True\n",
    "corrupt_dataset = False\n",
    "\n",
    "n_epochs = 30\n",
    "z_dim = 64\n",
    "display_step = 500\n",
    "compute_fid_every_x_epochs = 5\n",
    "batch_size = 128\n",
    "lr = 0.0002\n",
    "beta_1 = 0.5\n",
    "beta_2 = 0.999\n",
    "device = 'cuda'\n",
    "path_mnist_png = '../../data/MNIST/png/train'\n",
    "\n",
    "if architecture == 'DCGAN': \n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    crit_repeats = 1\n",
    "    r1_gamma = 10\n",
    "elif architecture == 'WGAN-GP':\n",
    "    crit_repeats = 5\n",
    "    c_lambda = 10\n",
    "\n",
    "im_shape = (1, 28, 28)\n",
    "n_classes = 10 if conditional else 0 # number of classes\n",
    "im_chan = im_shape[0] # 1 for black and white\n",
    "\n",
    "corruption_transform = transforms.Lambda(\n",
    "    lambda x: corrupt(np.uint8(x), \n",
    "    np.random.randint(1, 6), \n",
    "    corruption_name='gaussian_noise'))\n",
    "\n",
    "if corrupt_dataset:\n",
    "    transform = transforms.Compose([\n",
    "        corruption_transform,\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,)),\n",
    "    ])\n",
    "else:\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,)),\n",
    "    ])\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    MNIST('../../data', download=False, transform=transform),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_input_dim = z_dim + n_classes\n",
    "discriminator_im_chan = im_chan + n_classes\n",
    "\n",
    "gen = Generator_28(generator_input_dim).to(device)\n",
    "gen_opt = torch.optim.Adam(gen.parameters(), lr=lr, betas=(beta_1, beta_2))\n",
    "crit = Discriminator_28(discriminator_im_chan).to(device) \n",
    "crit_opt = torch.optim.Adam(crit.parameters(), lr=lr, betas=(beta_1, beta_2))\n",
    "\n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "    if isinstance(m, nn.BatchNorm2d):\n",
    "        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias, 0)\n",
    "gen = gen.apply(weights_init)\n",
    "crit = crit.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cur_step = 0\n",
    "generator_losses = []\n",
    "critic_losses = []\n",
    "fids = []\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    # Dataloader returns the batches\n",
    "    for real, labels in tqdm(dataloader):\n",
    "        cur_batch_size = len(real)\n",
    "        real = real.to(device)\n",
    "\n",
    "        # Format labels\n",
    "        if conditional:\n",
    "            one_hot_labels = nn.functional.one_hot(labels.to(device), n_classes)\n",
    "            image_one_hot_labels = one_hot_labels[:, :, None, None]\n",
    "            image_one_hot_labels = image_one_hot_labels.repeat(1, 1, im_shape[1], im_shape[2])\n",
    "\n",
    "        mean_iteration_critic_loss = 0\n",
    "        for _ in range(crit_repeats):\n",
    "            ### Update critic/discriminator ###\n",
    "            crit_opt.zero_grad()\n",
    "            fake_noise = get_noise(cur_batch_size, z_dim, device=device)\n",
    "            if conditional:\n",
    "                noise_and_labels = torch.cat((fake_noise.float(), one_hot_labels.float()), dim=1)\n",
    "                fake = gen(noise_and_labels)\n",
    "                fake_image_and_labels = torch.cat((fake.detach().float(), image_one_hot_labels.float()), dim=1)\n",
    "                real_image_and_labels = torch.cat((real.float(), image_one_hot_labels.float()), dim=1)\n",
    "                crit_fake_pred = crit(fake_image_and_labels)\n",
    "                crit_real_pred = crit(real_image_and_labels)\n",
    "            else:\n",
    "                fake = gen(fake_noise)\n",
    "                crit_fake_pred = crit(fake.detach())\n",
    "                crit_real_pred = crit(real)\n",
    "\n",
    "            if architecture == 'DCGAN':\n",
    "                crit_fake_loss = criterion(crit_fake_pred, torch.zeros_like(crit_fake_pred))\n",
    "                crit_real_loss = criterion(crit_real_pred, torch.ones_like(crit_real_pred))\n",
    "                crit_loss = (crit_fake_loss + crit_real_loss) / 2\n",
    "                if r1_gamma > 0: # R1 regularisation from https://github.com/NVlabs/stylegan2-ada-pytorch/blob/main/training/loss.py\n",
    "                    if conditional:\n",
    "                        real_tmp = real_image_and_labels.detach().requires_grad_(True)\n",
    "                    else:\n",
    "                        real_tmp = real.detach().requires_grad_(True)\n",
    "                    crit_real_pred_tmp = crit(real_tmp)\n",
    "                    r1_grads = torch.autograd.grad(outputs=crit_real_pred_tmp.sum(), inputs=real_tmp, create_graph=True)[0]\n",
    "                    # r1_grads = torch.autograd.grad(outputs=crit_real_pred_tmp, inputs=real_tmp, create_graph=True, grad_outputs=torch.ones_like(crit_real_pred))[0]\n",
    "                    # r1_grads = r1_grads.view(r1_grads.shape[0], -1)\n",
    "                    # r1_penalty = r1_grads.norm(2, dim=1).mean()\n",
    "                    r1_penalty = r1_grads.square().sum([1,2,3]).mean()\n",
    "                    loss_Dr1 = r1_penalty * (r1_gamma / 2)\n",
    "                    crit_loss += loss_Dr1\n",
    "            elif architecture == 'WGAN-GP':\n",
    "                epsilon = torch.rand(len(real), 1, 1, 1, device=device, requires_grad=True)\n",
    "                if conditional:\n",
    "                    gp = get_gradient_penalty(crit, real_image_and_labels, fake_image_and_labels.detach(), epsilon)\n",
    "                else:\n",
    "                    gp = get_gradient_penalty(crit, real, fake.detach(), epsilon)\n",
    "                crit_loss = torch.mean(crit_fake_pred - crit_real_pred) + c_lambda*gp\n",
    "\n",
    "            # Keep track of the average critic loss in this batch\n",
    "            mean_iteration_critic_loss += crit_loss.item() / crit_repeats\n",
    "            # Update gradients\n",
    "            crit_loss.backward(retain_graph=True)\n",
    "            # Update optimizer\n",
    "            crit_opt.step()\n",
    "        critic_losses += [mean_iteration_critic_loss]\n",
    "\n",
    "        ### Update generator ###\n",
    "        gen_opt.zero_grad()\n",
    "        if conditional: # WHY DO NOT GENERATE AGAIN NEW FAKES?\n",
    "            fake_image_and_labels = torch.cat((fake.float(), image_one_hot_labels.float()), dim=1)\n",
    "            crit_fake_pred = crit(fake_image_and_labels)\n",
    "        else:\n",
    "            fake_noise_2 = get_noise(cur_batch_size, z_dim, device=device)\n",
    "            fake_2 = gen(fake_noise_2)\n",
    "            crit_fake_pred = crit(fake_2)\n",
    "        \n",
    "        if architecture == 'DCGAN':\n",
    "            gen_loss = criterion(crit_fake_pred, torch.ones_like(crit_fake_pred))\n",
    "        elif architecture == 'WGAN-GP':\n",
    "            # gen_loss = get_gen_loss(crit_fake_pred)\n",
    "            gen_loss = -torch.mean(crit_fake_pred)\n",
    "        gen_loss.backward()\n",
    "\n",
    "        # Update the weights\n",
    "        gen_opt.step()\n",
    "\n",
    "        # Keep track of the average generator loss\n",
    "        generator_losses += [gen_loss.item()]\n",
    "\n",
    "\n",
    "        ### Visualization code ###\n",
    "        if cur_step % display_step == 0 and cur_step > 0:\n",
    "            gen_mean = sum(generator_losses[-display_step:]) / display_step\n",
    "            crit_mean = sum(critic_losses[-display_step:]) / display_step\n",
    "            print(f\"Epoch {epoch}, step {cur_step}: Generator loss: {gen_mean}, critic loss: {crit_mean}\")\n",
    "            show_tensor_images(fake)\n",
    "            # show_tensor_images(real)\n",
    "            step_bins = 20\n",
    "            num_examples = (len(generator_losses) // step_bins) * step_bins\n",
    "            plt.plot(\n",
    "                range(num_examples // step_bins), \n",
    "                torch.Tensor(generator_losses[:num_examples]).view(-1, step_bins).mean(1),\n",
    "                label=\"Generator Loss\"\n",
    "            )\n",
    "            plt.plot(\n",
    "                range(num_examples // step_bins), \n",
    "                torch.Tensor(critic_losses[:num_examples]).view(-1, step_bins).mean(1),\n",
    "                label=\"Critic Loss\"\n",
    "            )\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "            plt.figure()\n",
    "            plt.plot(np.arange(1, epoch+1, compute_fid_every_x_epochs), fids)\n",
    "            plt.xlabel('Epochs')\n",
    "            plt.ylabel('FID')\n",
    "            plt.show()\n",
    "\n",
    "        cur_step += 1\n",
    "        \n",
    "        \n",
    "    # Compute FID\n",
    "    if epoch == 1 or epoch % compute_fid_every_x_epochs == 0:\n",
    "        fid = compute_fid(gen, conditional, n_classes, path_mnist_png)\n",
    "        fids.append(fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cond_str = '_conditional' if conditional else ''\n",
    "# corrupted_str = '_corrupted' if corrupt_dataset else ''\n",
    "# fname = f'../models/{architecture}{cond_str}{corrupted_str}_MNIST_weights_{datetime.now().strftime(\"%Y%m%d_%H%M\")}.pth'\n",
    "# torch.save(gen.state_dict(), fname)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6be6e33523af32dc6473546410661d94332fff7d66a5861feb1339a525fe6522"
  },
  "kernelspec": {
   "display_name": "my-pipenv",
   "language": "python",
   "name": "my-pipenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
