{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import assign_free_gpus\n",
    "assign_free_gpus()\n",
    "\n",
    "import time\n",
    "import json\n",
    "from pathlib import Path\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn')\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from generate_data import MoonsDataModule, MoonsDataset\n",
    "from models import LinearClassifier, Classifier, GAN\n",
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "rng = np.random.default_rng(0)\n",
    "path_results = Path.cwd().parent.parent / 'results' / 'moons'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = 0.3\n",
    "linear = False\n",
    "path_classifier = path_results / 'classifier' / '2023-05-24_095926_noise0.3' / 'checkpoints' / 'epoch=99-step=6300.ckpt'\n",
    "# path_gan = path_results / 'GAN' / '2023-05-24_103512_noise0.3_classCondone-hot_classifCondMSP' / 'checkpoints' / 'epoch=99-step=12600.ckpt'\n",
    "path_gan = path_results / 'GAN' / '2023-06-08_162712_noise0.3_classCondone-hot_classifCondMSP' / 'checkpoints' / 'epoch=499-step=63000.ckpt'\n",
    "classifier = Classifier.load_from_checkpoint(str(path_classifier))\n",
    "\n",
    "# noise = 0.3\n",
    "# linear = True\n",
    "# path_classifier = path_results / 'classifier' / '2023-05-24_100150_noise0.3_linear' / 'checkpoints' / 'epoch=99-step=6300.ckpt'\n",
    "# path_gan = path_results / 'GAN' / '2023-05-24_103603_noise0.3_classCondone-hot_classifCondMSP_linear' / 'checkpoints' / 'epoch=99-step=12600.ckpt'\n",
    "# classifier = LinearClassifier.load_from_checkpoint(str(path_classifier))\n",
    "\n",
    "gan = GAN.load_from_checkpoint(str(path_gan), classifier=classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = MoonsDataset(n_samples=5000, noise=noise, random_state=2)\n",
    "x_test = data_test.x\n",
    "y_test = data_test.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(accelerator='auto', devices=1)\n",
    "trainer.validate(classifier, datamodule=MoonsDataModule(n_samples=20000, noise=noise, random_state=2))\n",
    "\n",
    "# SHOW DESCISION BOUNDARY\n",
    "x = np.linspace(-2, 3, 100)\n",
    "y = np.linspace(-2, 2, 100)\n",
    "\n",
    "grid_data = np.zeros((len(x)*len(y), 2))\n",
    "i = 0\n",
    "for x_ in x:\n",
    "    for y_ in y:\n",
    "        grid_data[i] = [x_, y_]\n",
    "        i += 1\n",
    "grid_data = torch.from_numpy(grid_data).float()\n",
    "\n",
    "with torch.no_grad():\n",
    "    y = classifier(grid_data)\n",
    "class_pred_grid = torch.sigmoid(y).round().cpu().flatten()#.numpy()\n",
    "\n",
    "# SHOW CLASSIF LOSS\n",
    "with torch.no_grad():\n",
    "    logits = classifier(x_test)\n",
    "    classif_loss = F.binary_cross_entropy_with_logits(logits.squeeze(), y_test, reduction='none')\n",
    "    \n",
    "# CORRECT PRED\n",
    "class_pred = torch.sigmoid(logits).round().cpu().flatten()\n",
    "classif_loss = class_pred != y_test\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "# ax.set_title('classifier decision boundary')\n",
    "ax.scatter(grid_data[class_pred_grid==0, 0], grid_data[class_pred_grid==0, 1], alpha=1, c='C0', label='predicted class 0')\n",
    "ax.scatter(grid_data[class_pred_grid!=0, 0], grid_data[class_pred_grid!=0, 1], alpha=1, c='C1', label='predicted class 1')\n",
    "ax.scatter(x_test[y_test==0, 0], x_test[y_test==0, 1], alpha=0.2, c=classif_loss[y_test==0], cmap='Reds', marker='o', label='real data - class 0')\n",
    "im = ax.scatter(x_test[y_test==1, 0], x_test[y_test==1, 1], alpha=0.2, c=classif_loss[y_test==1], cmap='Reds', marker='+', label='real data - class 1')\n",
    "leg = ax.legend(frameon=True)\n",
    "for lh in leg.legendHandles: \n",
    "    lh.set_alpha(1)\n",
    "# cbar = fig.colorbar(im, ax=ax, label='prediction error')\n",
    "# cbar.solids.set(alpha=1)\n",
    "\n",
    "plt.savefig('results_moons_classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_MSP(dataloader, classifier, device):\n",
    "\n",
    "    classifier.eval()\n",
    "    msp = torch.zeros((len(dataloader.dataset)))\n",
    "    # tcp = torch.zeros((len(dataloader.dataset)))\n",
    "    idx = 0\n",
    "    for X, y in dataloader:\n",
    "        batch_size = X.shape[0]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = classifier(X)\n",
    "        probas_class1 = torch.sigmoid(logits).squeeze()\n",
    "        probas_class0 = 1 - probas_class1\n",
    "        msp[idx:idx+batch_size] = torch.maximum(probas_class0, probas_class1)\n",
    "        idx += batch_size\n",
    "\n",
    "    return msp\n",
    "\n",
    "msp_test = get_MSP(DataLoader(data_test, 1000), classifier, device)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "ax.set_xlabel('MSP value')\n",
    "ax.hist(msp_test, alpha=0.5, bins=50, log=False)\n",
    "\n",
    "plt.savefig('results_moons_classifier_MSP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = len(x_test)\n",
    "z = torch.randn(n_samples, gan.latent_dim, device=gan.device)\n",
    "# if gan.condition_dim > 0:\n",
    "rnd_label = torch.randint(2, size=(z.shape[0],), device=gan.device)\n",
    "c = F.one_hot(rnd_label, num_classes=2)\n",
    "confidence = 0.999*torch.ones((n_samples, 1), device=gan.device)\n",
    "# confidence = torch.rand((n_samples, 1), device=gan.device)\n",
    "z = torch.cat([z, c, confidence], dim=1)\n",
    "with torch.no_grad():\n",
    "    w = gan.generator.mapping(z)\n",
    "    x_fake = gan.generator.synthesis(w).detach().cpu().numpy()\n",
    "    rnd_label = rnd_label.cpu().numpy()\n",
    "    w = w.detach().cpu().numpy()\n",
    "\n",
    "plt.figure()\n",
    "plt.title('fake vs. real data')\n",
    "plt.scatter(x_test[y_test==0, 0], x_test[y_test==0, 1], alpha=0.1, c='C0', label='real data - class 0')\n",
    "plt.scatter(x_test[y_test==1, 0], x_test[y_test==1, 1], alpha=0.1, c='C1', label='real data - class 1')\n",
    "plt.scatter(x_fake[rnd_label==0, 0], x_fake[rnd_label==0, 1], alpha=0.1, c='C2', label='fake data - class 0')\n",
    "plt.scatter(x_fake[rnd_label==1, 0], x_fake[rnd_label==1, 1], alpha=0.1, c='C3', label='fake data - class 1')\n",
    "leg = plt.legend()\n",
    "for lh in leg.legendHandles: \n",
    "    lh.set_alpha(1)\n",
    "\n",
    "# w_embedded = TSNE(n_components=2, learning_rate='auto', init='random').fit_transform(w)\n",
    "# plt.figure()\n",
    "# plt.title('t-SNE in W')\n",
    "# plt.scatter(w_embedded[rnd_label==0, 0], w_embedded[rnd_label==0, 1], alpha=0.5, c='C0', label='class 0')\n",
    "# plt.scatter(w_embedded[rnd_label==1, 0], w_embedded[rnd_label==1, 1], alpha=0.5, c='C1', label='class 1')\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate fake data conditioned by class and msp\n",
    "n_samples = len(x_test)\n",
    "z = torch.randn(n_samples, gan.latent_dim, device=gan.device)\n",
    "if gan.condition_dim > 0:\n",
    "    rnd_label = torch.randint(2, size=(z.shape[0],), device=gan.device)\n",
    "    c = F.one_hot(rnd_label, num_classes=2)\n",
    "    # confidence = 0.2*torch.ones((n_samples, 1), device=gan.device)\n",
    "    # confidence = torch.rand((n_samples, 1), device=gan.device)\n",
    "    confidence = msp_test[torch.randperm(msp_test.shape[0])].unsqueeze(1)\n",
    "    z = torch.cat([z, c, confidence], dim=1)\n",
    "with torch.no_grad():\n",
    "    w = gan.generator.mapping(z)\n",
    "    x_fake = gan.generator.synthesis(w).detach().cpu().numpy()\n",
    "\n",
    "# confidence\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8,4), constrained_layout=True)\n",
    "# ax1.set_title('MSP computed from real data')\n",
    "# ax2.set_title('generated data conditioned by MSP')\n",
    "scat1 = ax1.scatter(x_test[:, 0].cpu().numpy(), x_test[:, 1].cpu().numpy(), c=msp_test.cpu().numpy(), cmap='viridis', alpha=0.5)\n",
    "scat2 = ax2.scatter(x_fake[:, 0], x_fake[:, 1], c=confidence.cpu().numpy(), cmap='viridis', alpha=0.5)\n",
    "cb = fig.colorbar(scat2, ax=ax2, label='MSP')\n",
    "cb.set_alpha(1)\n",
    "cb.draw_all()\n",
    "for ax in [ax1, ax2]:\n",
    "    ax.set_xlim([-2, 3])\n",
    "    ax.set_ylim([-1.5, 2])\n",
    "    \n",
    "plt.savefig('results_moons_generator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    logits = classifier(torch.from_numpy(x_fake))\n",
    "    probas_class1 = torch.sigmoid(logits).squeeze()\n",
    "    probas_class0 = 1 - probas_class1\n",
    "    confidence_out = torch.maximum(probas_class0, probas_class1)\n",
    "    \n",
    "\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.plot([0.5, 1], [0.5, 1])\n",
    "plt.scatter(confidence.cpu(), confidence_out.cpu(), alpha=0.5)\n",
    "plt.xlabel('confidence in')\n",
    "plt.ylabel('confidence out')\n",
    "\n",
    "plt.savefig('results_moons_generator_MSP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "f9f85f796d01129d0dd105a088854619f454435301f6ffec2fea96ecbd9be4ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
