{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./moons') \n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import time\n",
    "import json\n",
    "from pathlib import Path\n",
    "import sklearn\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn')\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "# from pytorch_lightning.loggers import TensorBoardLogger\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from generate_data import MoonsDataModule, MoonsDataset\n",
    "from models import LinearClassifier, Classifier, GAN\n",
    "from temperature_scaling import ModelWithTemperature, _ECELoss\n",
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "rng = np.random.default_rng(0)\n",
    "path_models = Path.cwd().parent / 'models' / 'moons'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data, classifer, and GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = 0.3\n",
    "linear = False\n",
    "path_classifier = path_models / 'classifier' / '2023-05-24_095926_noise0.3' / 'checkpoints' / 'epoch=99-step=6300.ckpt'\n",
    "classifier = Classifier.load_from_checkpoint(str(path_classifier)).eval().to(device)\n",
    "\n",
    "# path_gan = path_models / 'GAN' / '2023-05-24_103512_noise0.3_classCondone-hot_classifCondMSP' / 'checkpoints' / 'epoch=99-step=12600.ckpt'\n",
    "# path_gan = path_models / 'GAN' / '2023-06-08_162712_noise0.3_classCondone-hot_classifCondMSP' / 'checkpoints' / 'epoch=499-step=63000.ckpt'\n",
    "path_gan = path_models / 'GAN' / '2023-06-08_133522_noise0.3_classCondone-hot_classifCondNone' / 'checkpoints' / 'epoch=199-step=25200.ckpt'\n",
    "gan = GAN.load_from_checkpoint(str(path_gan), classifier=classifier).eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = MoonsDataset(n_samples=10000, noise=noise, random_state=2)\n",
    "x_test = data_test.x\n",
    "y_test = data_test.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(accelerator='auto', devices=1)\n",
    "trainer.validate(classifier, datamodule=MoonsDataModule(n_samples=20000, noise=noise, random_state=2))\n",
    "\n",
    "# SHOW DESCISION BOUNDARY\n",
    "x = np.linspace(-2, 3, 100)\n",
    "y = np.linspace(-2, 2, 100)\n",
    "\n",
    "grid_data = np.zeros((len(x)*len(y), 2))\n",
    "i = 0\n",
    "for x_ in x:\n",
    "    for y_ in y:\n",
    "        grid_data[i] = [x_, y_]\n",
    "        i += 1\n",
    "grid_data = torch.from_numpy(grid_data).float()\n",
    "\n",
    "with torch.no_grad():\n",
    "    y = classifier(grid_data)\n",
    "class_pred_grid = torch.sigmoid(y).round().cpu().flatten()#.numpy()\n",
    "\n",
    "# SHOW CLASSIF LOSS\n",
    "with torch.no_grad():\n",
    "    logits = classifier(x_test)\n",
    "    classif_loss = F.binary_cross_entropy_with_logits(logits.squeeze(), y_test, reduction='none')\n",
    "    \n",
    "# CORRECT PRED\n",
    "class_pred = torch.sigmoid(logits).round().cpu().flatten()\n",
    "classif_loss = class_pred != y_test\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "# ax.set_title('classifier decision boundary')\n",
    "ax.scatter(grid_data[class_pred_grid==0, 0], grid_data[class_pred_grid==0, 1], alpha=1, c='C0', label='predicted class 0')\n",
    "ax.scatter(grid_data[class_pred_grid!=0, 0], grid_data[class_pred_grid!=0, 1], alpha=1, c='C1', label='predicted class 1')\n",
    "ax.scatter(x_test[y_test==0, 0], x_test[y_test==0, 1], alpha=0.2, c=classif_loss[y_test==0], cmap='Reds', marker='o', label='real data - class 0')\n",
    "im = ax.scatter(x_test[y_test==1, 0], x_test[y_test==1, 1], alpha=0.2, c=classif_loss[y_test==1], cmap='Reds', marker='+', label='real data - class 1')\n",
    "leg = ax.legend(frameon=True)\n",
    "for lh in leg.legendHandles: \n",
    "    lh.set_alpha(1)\n",
    "# cbar = fig.colorbar(im, ax=ax, label='prediction error')\n",
    "# cbar.solids.set(alpha=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_MSP_correct(dataloader, classifier, device):\n",
    "\n",
    "    classifier.eval()\n",
    "    msp = torch.zeros((len(dataloader.dataset)), device=device)\n",
    "    correct = torch.zeros((len(dataloader.dataset)), device=device)\n",
    "    idx = 0\n",
    "    for X, y in dataloader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        batch_size = X.shape[0]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = classifier(X)\n",
    "        probas_class1 = torch.sigmoid(logits).squeeze()\n",
    "        probas_class0 = 1 - probas_class1\n",
    "        msp[idx:idx+batch_size] = torch.maximum(probas_class0, probas_class1)\n",
    "        correct[idx:idx+batch_size] = probas_class1.round() == y\n",
    "        idx += batch_size\n",
    "\n",
    "    return msp, correct\n",
    "\n",
    "msp_test, correct_test = get_MSP_correct(DataLoader(data_test, 1000), classifier.to(device), device)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "ax.set_xlabel('MSP value')\n",
    "ax.hist(msp_test.cpu(), alpha=0.5, bins=50, log=False);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = len(x_test)\n",
    "z = torch.randn(n_samples, gan.latent_dim, device=gan.device)\n",
    "# if gan.condition_dim > 0:\n",
    "rnd_label = torch.randint(2, size=(z.shape[0],), device=gan.device)\n",
    "c = F.one_hot(rnd_label, num_classes=2)\n",
    "confidence = get_MSP_correct(DataLoader(MoonsDataset(n_samples=n_samples, noise=noise, random_state=None), 1000), classifier.to(device), device)[0].unsqueeze(1) # labels from real distrib\n",
    "# confidence = 0.999*torch.ones((n_samples, 1), device=gan.device)\n",
    "# confidence = torch.rand((n_samples, 1), device=gan.device)\n",
    "\n",
    "if gan.classifier_conditioning is not None:\n",
    "    c = torch.cat([c, confidence], dim=1)\n",
    "z = torch.cat([z, c], dim=1)\n",
    "with torch.no_grad():\n",
    "    w = gan.generator.mapping(z)\n",
    "    x_fake = gan.generator.synthesis(w).detach().cpu().numpy()\n",
    "    rnd_label = rnd_label.cpu().numpy()\n",
    "    w = w.detach().cpu().numpy()\n",
    "\n",
    "plt.figure()\n",
    "plt.title('fake vs. real data')\n",
    "plt.scatter(x_test[y_test==0, 0], x_test[y_test==0, 1], alpha=0.1, c='C0', label='real data - class 0')\n",
    "plt.scatter(x_test[y_test==1, 0], x_test[y_test==1, 1], alpha=0.1, c='C1', label='real data - class 1')\n",
    "plt.scatter(x_fake[rnd_label==0, 0], x_fake[rnd_label==0, 1], alpha=0.1, c='C2', label='fake data - class 0')\n",
    "plt.scatter(x_fake[rnd_label==1, 0], x_fake[rnd_label==1, 1], alpha=0.1, c='C3', label='fake data - class 1')\n",
    "leg = plt.legend()\n",
    "for lh in leg.legendHandles: \n",
    "    lh.set_alpha(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful functions for calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ece_from_dataloader(model, dataloader):\n",
    "    # First: collect all the logits and labels for the validation set\n",
    "    logits_list = []\n",
    "    labels_list = []\n",
    "    with torch.no_grad():\n",
    "        for input, label in dataloader:\n",
    "            input = input.cuda()\n",
    "            logits = model(input)\n",
    "            logits_list.append(logits)\n",
    "            labels_list.append(label)\n",
    "        logits = torch.cat(logits_list).cuda()\n",
    "        labels = torch.cat(labels_list).cuda()\n",
    "\n",
    "    ece = _ECELoss()(logits, labels)\n",
    "\n",
    "    return ece"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calibration data from real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1000\n",
    "\n",
    "all_ece_calib_before_TS = {}\n",
    "all_ece_test_before_TS = {}\n",
    "all_ece_calib_after_TS = {}\n",
    "all_ece_test_after_TS = {}\n",
    "\n",
    "test_loader = DataLoader(MoonsDataset(n_samples=20000, noise=noise, random_state=2), batch_size=batch_size)\n",
    "\n",
    "for valid_size in np.geomspace(100, 10000, 5, dtype=int):\n",
    "    print(f'Calibration set size: {valid_size}')\n",
    "    all_ece_calib_before_TS[valid_size] = []\n",
    "    all_ece_test_before_TS[valid_size] = []\n",
    "    all_ece_calib_after_TS[valid_size] = []\n",
    "    all_ece_test_after_TS[valid_size] = []\n",
    "\n",
    "    for trial in range(10):\n",
    "\n",
    "        valid_loader = DataLoader(MoonsDataset(n_samples=valid_size, noise=noise, random_state=None), batch_size=batch_size)\n",
    "\n",
    "        ece_calib_before_TS = ece_from_dataloader(classifier, valid_loader)\n",
    "        ece_test_before_TS = ece_from_dataloader(classifier, test_loader)\n",
    "\n",
    "        # Performing temperature scaling\n",
    "        model = ModelWithTemperature(classifier).to(device)\n",
    "        model.set_temperature(valid_loader, binary_classif=True)\n",
    "\n",
    "        ece_calib_after_TS = ece_from_dataloader(model, valid_loader)\n",
    "        ece_test_after_TS = ece_from_dataloader(model, test_loader)\n",
    "\n",
    "        all_ece_calib_before_TS[valid_size] += [ece_calib_before_TS.item()]\n",
    "        all_ece_test_before_TS[valid_size] += [ece_test_before_TS.item()]\n",
    "        all_ece_calib_after_TS[valid_size] += [ece_calib_after_TS.item()]\n",
    "        all_ece_test_after_TS[valid_size] += [ece_test_after_TS.item()]\n",
    "\n",
    "\n",
    "# PLOT\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "means = np.array([np.mean(v) for v in all_ece_calib_before_TS.values()])\n",
    "stds = np.array([np.std(v) for v in all_ece_calib_before_TS.values()])\n",
    "ax.plot(all_ece_calib_before_TS.keys(), means, label='ECE calib before TS')\n",
    "ax.fill_between(all_ece_calib_before_TS.keys(), means-stds, means+stds, alpha=0.5)\n",
    "\n",
    "means = np.array([np.mean(v) for v in all_ece_calib_after_TS.values()])\n",
    "stds = np.array([np.std(v) for v in all_ece_calib_after_TS.values()])\n",
    "ax.plot(all_ece_calib_after_TS.keys(), means, label='ECE calib after TS')\n",
    "ax.fill_between(all_ece_calib_after_TS.keys(), means-stds, means+stds, alpha=0.5)\n",
    "\n",
    "means = np.array([np.mean(v) for v in all_ece_test_before_TS.values()])\n",
    "stds = np.array([np.std(v) for v in all_ece_test_before_TS.values()])\n",
    "ax.plot(all_ece_test_before_TS.keys(), means, label='ECE test before TS')\n",
    "ax.fill_between(all_ece_test_before_TS.keys(), means-stds, means+stds, alpha=0.5)\n",
    "\n",
    "means = np.array([np.mean(v) for v in all_ece_test_after_TS.values()])\n",
    "stds = np.array([np.std(v) for v in all_ece_test_after_TS.values()])\n",
    "ax.plot(all_ece_test_after_TS.keys(), means, label='ECE test after TS')\n",
    "ax.fill_between(all_ece_test_after_TS.keys(), means-stds, means+stds, alpha=0.5)\n",
    "ax.set_xlabel('Calibration set size')\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ece_test_after_TS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calibration data from synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_synthetic_dataset(n_samples=20000):\n",
    "\n",
    "    z = torch.randn(n_samples, gan.latent_dim, device=gan.device)\n",
    "    # if gan.condition_dim > 0:\n",
    "    rnd_label = torch.randint(2, size=(z.shape[0],), device=gan.device)\n",
    "    c = F.one_hot(rnd_label, num_classes=2)\n",
    "    confidence = get_MSP_correct(DataLoader(MoonsDataset(n_samples=n_samples, noise=noise, random_state=None), 1000), classifier.to(device), device)[0].unsqueeze(1) # confidence from real distrib\n",
    "    # confidence = 0.999*torch.ones((n_samples, 1), device=gan.device) # fixed confidence\n",
    "    # confidence = 0.5 + 0.5*torch.rand((n_samples, 1), device=gan.device) # uniform confidence\n",
    "    if gan.classifier_conditioning is not None:\n",
    "        c = torch.cat([c, confidence], dim=1)\n",
    "    z = torch.cat([z, c], dim=1)\n",
    "    with torch.no_grad():\n",
    "        w = gan.generator.mapping(z)\n",
    "        x_fake = gan.generator.synthesis(w).detach().cpu().numpy()\n",
    "\n",
    "    class SyntheticDataset(Dataset):\n",
    "\n",
    "        def __init__(self, x, y):\n",
    "            self.x = x\n",
    "            self.y = y\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.x)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            return self.x[idx], self.y[idx]\n",
    "\n",
    "    synthetic_data = SyntheticDataset(x_fake, rnd_label.cpu().numpy().astype(float))\n",
    "\n",
    "    return synthetic_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1000\n",
    "\n",
    "all_ece_calib_before_TS = {}\n",
    "all_ece_test_before_TS = {}\n",
    "all_ece_calib_after_TS = {}\n",
    "all_ece_test_after_TS = {}\n",
    "\n",
    "test_loader = DataLoader(MoonsDataset(n_samples=20000, noise=noise, random_state=2), batch_size=batch_size)\n",
    "\n",
    "for valid_size in np.linspace(100, 10000, 3, dtype=int):\n",
    "    print(f'Calibration set size: {valid_size}')\n",
    "    all_ece_calib_before_TS[valid_size] = []\n",
    "    all_ece_test_before_TS[valid_size] = []\n",
    "    all_ece_calib_after_TS[valid_size] = []\n",
    "    all_ece_test_after_TS[valid_size] = []\n",
    "\n",
    "    for trial in range(10):\n",
    "        synthetic_data = create_synthetic_dataset(valid_size)\n",
    "        valid_loader = DataLoader(synthetic_data, batch_size=batch_size)\n",
    "        ece_calib_before_TS = ece_from_dataloader(classifier, valid_loader)\n",
    "        ece_test_before_TS = ece_from_dataloader(classifier, test_loader)\n",
    "\n",
    "        # Performing temperature scaling\n",
    "        model = ModelWithTemperature(classifier).to(device)\n",
    "        model.set_temperature(valid_loader, binary_classif=True)\n",
    "\n",
    "        ece_calib_after_TS = ece_from_dataloader(model, valid_loader)\n",
    "        ece_test_after_TS = ece_from_dataloader(model, test_loader)\n",
    "\n",
    "        all_ece_calib_before_TS[valid_size] += [ece_calib_before_TS.item()]\n",
    "        all_ece_test_before_TS[valid_size] += [ece_test_before_TS.item()]\n",
    "        all_ece_calib_after_TS[valid_size] += [ece_calib_after_TS.item()]\n",
    "        all_ece_test_after_TS[valid_size] += [ece_test_after_TS.item()]\n",
    "\n",
    "\n",
    "# PLOT\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "means = np.array([np.mean(v) for v in all_ece_calib_before_TS.values()])\n",
    "stds = np.array([np.std(v) for v in all_ece_calib_before_TS.values()])\n",
    "ax.plot(all_ece_calib_before_TS.keys(), means, label='ECE calib before TS')\n",
    "ax.fill_between(all_ece_calib_before_TS.keys(), means-stds, means+stds, alpha=0.5)\n",
    "\n",
    "means = np.array([np.mean(v) for v in all_ece_calib_after_TS.values()])\n",
    "stds = np.array([np.std(v) for v in all_ece_calib_after_TS.values()])\n",
    "ax.plot(all_ece_calib_after_TS.keys(), means, label='ECE calib after TS')\n",
    "ax.fill_between(all_ece_calib_after_TS.keys(), means-stds, means+stds, alpha=0.5)\n",
    "\n",
    "means = np.array([np.mean(v) for v in all_ece_test_before_TS.values()])\n",
    "stds = np.array([np.std(v) for v in all_ece_test_before_TS.values()])\n",
    "ax.plot(all_ece_test_before_TS.keys(), means, label='ECE test before TS')\n",
    "ax.fill_between(all_ece_test_before_TS.keys(), means-stds, means+stds, alpha=0.5)\n",
    "\n",
    "means = np.array([np.mean(v) for v in all_ece_test_after_TS.values()])\n",
    "stds = np.array([np.std(v) for v in all_ece_test_after_TS.values()])\n",
    "ax.plot(all_ece_test_after_TS.keys(), means, label='ECE test after TS')\n",
    "ax.fill_between(all_ece_test_after_TS.keys(), means-stds, means+stds, alpha=0.5)\n",
    "ax.set_xlabel('Calibration set size')\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ece_test_after_TS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in test_loader:\n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
