{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "# from torchvision.datasets import CIFAR10\n",
    "# import sys\n",
    "# sys.path.append('./stylegan/stylegan2')\n",
    "# from benchmark_calibration import postprocess_synthetic_images, preprocess_images_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in [\n",
    "    Path('/d/alecoz/projects'), # DeepLab\n",
    "    Path(os.path.expandvars('$WORK')), # Jean Zay\n",
    "    Path('w:/')]: # local\n",
    "    if os.path.exists(p):\n",
    "        path_main = p / 'calibration-with-synthetic-data'\n",
    "path_results = path_main / 'results'\n",
    "path_models =  path_main / 'models/CIFAR10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_origins = [\n",
    "    'synthetic', 'synthetic filtered', \n",
    "    'validation', 'validation augmented', \n",
    "    'validation high confidence', 'validation low confidence'\n",
    "]\n",
    "dataset_sizes = [\n",
    "    \n",
    "]\n",
    "model_names = [\n",
    "    'densenet121', 'densenet161', 'densenet169',\n",
    "    'googlenet',\n",
    "    'inception_v3',\n",
    "    'mobilenet_v2',\n",
    "    'resnet18', 'resnet34', 'resnet50', \n",
    "    'vgg11_bn', 'vgg13_bn', 'vgg16_bn', 'vgg19_bn'\n",
    "    ]\n",
    "methods = ['baseline (no calibration)', 'temperature scaling', 'vector scaling']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset origin</th>\n",
       "      <th>dataset size</th>\n",
       "      <th>model</th>\n",
       "      <th>method</th>\n",
       "      <th>seed</th>\n",
       "      <th>ECE</th>\n",
       "      <th>SCE</th>\n",
       "      <th>RMSCE</th>\n",
       "      <th>ACE</th>\n",
       "      <th>TACE</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUROC</th>\n",
       "      <th>Coverage_for_Accuracy_99</th>\n",
       "      <th>Coverage_for_Accuracy_95</th>\n",
       "      <th>Coverage_for_Accuracy_90</th>\n",
       "      <th>AURC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>synthetic</td>\n",
       "      <td>1000</td>\n",
       "      <td>densenet121</td>\n",
       "      <td>baseline (no calibration)</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.022205</td>\n",
       "      <td>0.003330</td>\n",
       "      <td>0.057408</td>\n",
       "      <td>0.007698</td>\n",
       "      <td>0.044101</td>\n",
       "      <td>94.060001</td>\n",
       "      <td>0.871927</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.009478</td>\n",
       "      <td>0.001880</td>\n",
       "      <td>0.015375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>synthetic</td>\n",
       "      <td>1000</td>\n",
       "      <td>densenet121</td>\n",
       "      <td>temperature scaling</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.030767</td>\n",
       "      <td>0.004915</td>\n",
       "      <td>0.054757</td>\n",
       "      <td>0.008115</td>\n",
       "      <td>0.041341</td>\n",
       "      <td>94.060001</td>\n",
       "      <td>0.871548</td>\n",
       "      <td>0.002240</td>\n",
       "      <td>0.012398</td>\n",
       "      <td>0.002360</td>\n",
       "      <td>0.015407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>synthetic</td>\n",
       "      <td>1000</td>\n",
       "      <td>densenet121</td>\n",
       "      <td>vector scaling</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.021055</td>\n",
       "      <td>0.004355</td>\n",
       "      <td>0.042191</td>\n",
       "      <td>0.008588</td>\n",
       "      <td>0.037915</td>\n",
       "      <td>93.940000</td>\n",
       "      <td>0.843663</td>\n",
       "      <td>0.005199</td>\n",
       "      <td>0.035433</td>\n",
       "      <td>0.002799</td>\n",
       "      <td>0.017250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>synthetic</td>\n",
       "      <td>1000</td>\n",
       "      <td>densenet161</td>\n",
       "      <td>baseline (no calibration)</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.021215</td>\n",
       "      <td>0.003088</td>\n",
       "      <td>0.062704</td>\n",
       "      <td>0.008083</td>\n",
       "      <td>0.047961</td>\n",
       "      <td>93.988000</td>\n",
       "      <td>0.859910</td>\n",
       "      <td>0.002120</td>\n",
       "      <td>0.076745</td>\n",
       "      <td>0.000240</td>\n",
       "      <td>0.018076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>synthetic</td>\n",
       "      <td>1000</td>\n",
       "      <td>densenet161</td>\n",
       "      <td>temperature scaling</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.027246</td>\n",
       "      <td>0.004227</td>\n",
       "      <td>0.060249</td>\n",
       "      <td>0.008384</td>\n",
       "      <td>0.047564</td>\n",
       "      <td>93.988000</td>\n",
       "      <td>0.859682</td>\n",
       "      <td>0.001840</td>\n",
       "      <td>0.002719</td>\n",
       "      <td>0.003759</td>\n",
       "      <td>0.018105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397</th>\n",
       "      <td>validation low confidence</td>\n",
       "      <td>5000</td>\n",
       "      <td>vgg16_bn</td>\n",
       "      <td>temperature scaling</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.017531</td>\n",
       "      <td>0.002969</td>\n",
       "      <td>0.049991</td>\n",
       "      <td>0.006644</td>\n",
       "      <td>0.040182</td>\n",
       "      <td>93.936001</td>\n",
       "      <td>0.917471</td>\n",
       "      <td>0.001560</td>\n",
       "      <td>0.010278</td>\n",
       "      <td>0.006039</td>\n",
       "      <td>0.009400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1398</th>\n",
       "      <td>validation low confidence</td>\n",
       "      <td>5000</td>\n",
       "      <td>vgg16_bn</td>\n",
       "      <td>vector scaling</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.018333</td>\n",
       "      <td>0.002901</td>\n",
       "      <td>0.048255</td>\n",
       "      <td>0.006255</td>\n",
       "      <td>0.036687</td>\n",
       "      <td>93.844000</td>\n",
       "      <td>0.911564</td>\n",
       "      <td>0.002160</td>\n",
       "      <td>0.018196</td>\n",
       "      <td>0.001120</td>\n",
       "      <td>0.010093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1399</th>\n",
       "      <td>validation low confidence</td>\n",
       "      <td>5000</td>\n",
       "      <td>vgg19_bn</td>\n",
       "      <td>baseline (no calibration)</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.020657</td>\n",
       "      <td>0.004080</td>\n",
       "      <td>0.061233</td>\n",
       "      <td>0.006514</td>\n",
       "      <td>0.044683</td>\n",
       "      <td>94.051999</td>\n",
       "      <td>0.894471</td>\n",
       "      <td>0.001880</td>\n",
       "      <td>0.034193</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.012947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1400</th>\n",
       "      <td>validation low confidence</td>\n",
       "      <td>5000</td>\n",
       "      <td>vgg19_bn</td>\n",
       "      <td>temperature scaling</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.021623</td>\n",
       "      <td>0.003105</td>\n",
       "      <td>0.052763</td>\n",
       "      <td>0.006622</td>\n",
       "      <td>0.041402</td>\n",
       "      <td>94.051999</td>\n",
       "      <td>0.894053</td>\n",
       "      <td>0.001560</td>\n",
       "      <td>0.009878</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.012935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1401</th>\n",
       "      <td>validation low confidence</td>\n",
       "      <td>5000</td>\n",
       "      <td>vgg19_bn</td>\n",
       "      <td>vector scaling</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.020911</td>\n",
       "      <td>0.002961</td>\n",
       "      <td>0.048658</td>\n",
       "      <td>0.006407</td>\n",
       "      <td>0.037968</td>\n",
       "      <td>94.016000</td>\n",
       "      <td>0.887595</td>\n",
       "      <td>0.005439</td>\n",
       "      <td>0.068346</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.011936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1402 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 dataset origin  dataset size        model  \\\n",
       "0                     synthetic          1000  densenet121   \n",
       "1                     synthetic          1000  densenet121   \n",
       "2                     synthetic          1000  densenet121   \n",
       "3                     synthetic          1000  densenet161   \n",
       "4                     synthetic          1000  densenet161   \n",
       "...                         ...           ...          ...   \n",
       "1397  validation low confidence          5000     vgg16_bn   \n",
       "1398  validation low confidence          5000     vgg16_bn   \n",
       "1399  validation low confidence          5000     vgg19_bn   \n",
       "1400  validation low confidence          5000     vgg19_bn   \n",
       "1401  validation low confidence          5000     vgg19_bn   \n",
       "\n",
       "                         method  seed       ECE       SCE     RMSCE       ACE  \\\n",
       "0     baseline (no calibration)   2.0  0.022205  0.003330  0.057408  0.007698   \n",
       "1           temperature scaling   2.0  0.030767  0.004915  0.054757  0.008115   \n",
       "2                vector scaling   2.0  0.021055  0.004355  0.042191  0.008588   \n",
       "3     baseline (no calibration)   2.0  0.021215  0.003088  0.062704  0.008083   \n",
       "4           temperature scaling   2.0  0.027246  0.004227  0.060249  0.008384   \n",
       "...                         ...   ...       ...       ...       ...       ...   \n",
       "1397        temperature scaling   2.0  0.017531  0.002969  0.049991  0.006644   \n",
       "1398             vector scaling   2.0  0.018333  0.002901  0.048255  0.006255   \n",
       "1399  baseline (no calibration)   2.0  0.020657  0.004080  0.061233  0.006514   \n",
       "1400        temperature scaling   2.0  0.021623  0.003105  0.052763  0.006622   \n",
       "1401             vector scaling   2.0  0.020911  0.002961  0.048658  0.006407   \n",
       "\n",
       "          TACE   Accuracy     AUROC  Coverage_for_Accuracy_99  \\\n",
       "0     0.044101  94.060001  0.871927                  0.002200   \n",
       "1     0.041341  94.060001  0.871548                  0.002240   \n",
       "2     0.037915  93.940000  0.843663                  0.005199   \n",
       "3     0.047961  93.988000  0.859910                  0.002120   \n",
       "4     0.047564  93.988000  0.859682                  0.001840   \n",
       "...        ...        ...       ...                       ...   \n",
       "1397  0.040182  93.936001  0.917471                  0.001560   \n",
       "1398  0.036687  93.844000  0.911564                  0.002160   \n",
       "1399  0.044683  94.051999  0.894471                  0.001880   \n",
       "1400  0.041402  94.051999  0.894053                  0.001560   \n",
       "1401  0.037968  94.016000  0.887595                  0.005439   \n",
       "\n",
       "      Coverage_for_Accuracy_95  Coverage_for_Accuracy_90      AURC  \n",
       "0                     0.009478                  0.001880  0.015375  \n",
       "1                     0.012398                  0.002360  0.015407  \n",
       "2                     0.035433                  0.002799  0.017250  \n",
       "3                     0.076745                  0.000240  0.018076  \n",
       "4                     0.002719                  0.003759  0.018105  \n",
       "...                        ...                       ...       ...  \n",
       "1397                  0.010278                  0.006039  0.009400  \n",
       "1398                  0.018196                  0.001120  0.010093  \n",
       "1399                  0.034193                  0.000400  0.012947  \n",
       "1400                  0.009878                  0.000160  0.012935  \n",
       "1401                  0.068346                  0.000080  0.011936  \n",
       "\n",
       "[1402 rows x 16 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(path_results / 'benchmark_calibration_test.csv')\n",
    "# average over seeds\n",
    "df = df.groupby(['dataset origin', 'dataset size', 'model', 'method']).mean().reset_index()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method = 'temperature scaling' # temperature scaling, vector scaling\n",
    "metric = 'ECE'\n",
    "\n",
    "pivot_df = df[df['dataset size'] == 5000].pivot_table(index='model', columns=['method', 'dataset origin'], values=metric)\n",
    "pivot_df['No calibration'] = df[df['method'] == 'baseline (no calibration)'].pivot_table(index='model', values=metric)\n",
    "pivot_df = pivot_df[['No calibration', 'temperature scaling', 'vector scaling']]\n",
    "pivot_df = pivot_df[[col for col in pivot_df.columns if 'confidence' not in col[1]]]\n",
    "pivot_df = pivot_df[[col for col in pivot_df.columns if 'filtered' not in col[1]]]\n",
    "\n",
    "# format\n",
    "pivot_df.columns.name = 'Calibration data'\n",
    "pivot_df = pivot_df[\n",
    "    pd.MultiIndex.from_tuples([\n",
    "    ('No calibration', ''),\n",
    "    ('temperature scaling', 'validation'),\n",
    "    ('temperature scaling', 'validation augmented'),\n",
    "    ('temperature scaling', 'synthetic'),\n",
    "    ('vector scaling', 'validation'),\n",
    "    ('vector scaling', 'validation augmented'),\n",
    "    ('vector scaling', 'synthetic')])\n",
    "]\n",
    "pivot_df = 100*pivot_df\n",
    "\n",
    "s = pivot_df.round(2).style\n",
    "s = s.format('{:.2f}').highlight_min(axis=1, props=\"textbf:--rwrap;\") # min value per row in bold\n",
    "print(s.to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_models/'cifar10.pkl', 'rb') as f:\n",
    "    G = pickle.load(f)['G_ema'].cuda()\n",
    "\n",
    "n_images = 3\n",
    "fig, axs = plt.subplots(n_images, 10, figsize=(10, 3))\n",
    "for label in range(G.c_dim):\n",
    "\n",
    "    z = torch.randn([n_images, G.z_dim]).cuda() # latent codes\n",
    "    c = torch.nn.functional.one_hot(label*torch.ones((n_images,), dtype=int).cuda(), num_classes=G.c_dim) # class labels\n",
    "    img = G(z, c, truncation_psi=1) # NCHW, float32, dynamic range [-1, +1]\n",
    "    img = postprocess_synthetic_images(img).cpu()\n",
    "\n",
    "    for i in range(n_images):\n",
    "        ax = axs[i, label]\n",
    "        ax.imshow(img[i].permute(1,2,0))\n",
    "        ax.axis('off')  # Hide the axis\n",
    "plt.subplots_adjust(wspace=0, hspace=0)\n",
    "plt.savefig(path_results / 'synthetic_images.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = CIFAR10(root=os.path.expandvars('$DSDIR'), train=True)\n",
    "\n",
    "fig, axs = plt.subplots(n_images, 10, figsize=(10, 3))\n",
    "for label in range(G.c_dim):\n",
    "\n",
    "    imgs = []\n",
    "    while len(imgs) < n_images:\n",
    "        img, label_ = dataset_train[torch.randint(len(dataset_train), (1,)).item()]\n",
    "        if label_ == label:\n",
    "            imgs.append(img)\n",
    "\n",
    "    for i in range(n_images):\n",
    "        ax = axs[i, label]\n",
    "        ax.imshow(imgs[i])\n",
    "        ax.axis('off')  # Hide the axis\n",
    "plt.subplots_adjust(wspace=0, hspace=0)\n",
    "plt.savefig(path_results / 'real_images.png') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confidence values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrrr}\n",
      "method & No calibration & \\multicolumn{3}{r}{temperature scaling} & \\multicolumn{3}{r}{vector scaling} \\\\\n",
      "dataset origin &  & validation & validation low confidence & validation high confidence & validation & validation low confidence & validation high confidence \\\\\n",
      "model &  &  &  &  &  &  &  \\\\\n",
      "densenet121 & 2.22 & \\textbf{1.73} & 3.00 & 2.80 & 1.82 & 2.81 & 3.75 \\\\\n",
      "densenet161 & 2.12 & 1.99 & 2.80 & 2.36 & \\textbf{1.88} & 2.45 & 3.48 \\\\\n",
      "densenet169 & 2.54 & 2.29 & 2.93 & 2.69 & \\textbf{2.13} & 2.51 & 3.80 \\\\\n",
      "googlenet & 1.47 & 1.22 & \\textbf{1.02} & 2.01 & 1.25 & 1.13 & 5.31 \\\\\n",
      "inception_v3 & 1.98 & 1.58 & 2.29 & 2.61 & \\textbf{1.53} & 2.44 & 3.01 \\\\\n",
      "mobilenet_v2 & 2.59 & \\textbf{1.49} & 2.52 & 3.44 & \\textbf{1.49} & 2.83 & 8.99 \\\\\n",
      "resnet18 & 2.03 & 1.74 & 2.30 & 2.64 & \\textbf{1.56} & 1.87 & 4.25 \\\\\n",
      "resnet34 & 2.71 & 2.19 & 3.31 & 3.49 & \\textbf{2.17} & 2.81 & 5.42 \\\\\n",
      "resnet50 & 2.27 & \\textbf{1.62} & 2.79 & 3.10 & 1.81 & 2.77 & 5.39 \\\\\n",
      "vgg11_bn & 1.59 & 1.66 & 1.88 & 2.79 & \\textbf{1.43} & 1.56 & 7.28 \\\\\n",
      "vgg13_bn & 1.19 & \\textbf{1.17} & 1.44 & 2.57 & 1.19 & 1.32 & 4.79 \\\\\n",
      "vgg16_bn & 1.72 & \\textbf{1.68} & 2.60 & 3.22 & 1.72 & 2.70 & 4.99 \\\\\n",
      "vgg19_bn & \\textbf{2.07} & 2.18 & 3.30 & 2.77 & 2.19 & 2.94 & 4.40 \\\\\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metric = 'ECE'\n",
    "\n",
    "pivot_df = df[df['dataset size'] == 2500].pivot_table(index='model', columns=['method', 'dataset origin'], values=metric)\n",
    "pivot_df['No calibration'] = df[df['method'] == 'baseline (no calibration)'].pivot_table(index='model', values=metric)\n",
    "pivot_df = pivot_df[['No calibration', 'temperature scaling', 'vector scaling']]\n",
    "\n",
    "# format\n",
    "pivot_df.columns.name = 'Calibration data'\n",
    "pivot_df = pivot_df[\n",
    "    pd.MultiIndex.from_tuples([\n",
    "    ('No calibration', ''),\n",
    "    ('temperature scaling', 'validation'),\n",
    "    ('temperature scaling', 'validation low confidence'),\n",
    "    ('temperature scaling', 'validation high confidence'),\n",
    "    ('vector scaling', 'validation'),\n",
    "    ('vector scaling', 'validation low confidence'),\n",
    "    ('vector scaling', 'validation high confidence')])\n",
    "]\n",
    "pivot_df = 100*pivot_df\n",
    "\n",
    "s = pivot_df.round(2).style\n",
    "s = s.format('{:.2f}').highlight_min(axis=1, props=\"textbf:--rwrap;\") # min value per row in bold\n",
    "print(s.to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OTHER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Influence of dataset size\n",
    "\n",
    "Vector scaling always better than temperature scaling when looking at ACE. ACE also lowers with more data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_origin = 'validation'\n",
    "dataset_origin = 'synthetic'\n",
    "# dataset_origin = 'synthetic filtered'\n",
    "metric = 'ECE'\n",
    "\n",
    "fig, axs = plt.subplots(int(len(model_names)/3)+1, 3, figsize=(10, len(model_names)))\n",
    "fig.suptitle(f'Dataset origin: {dataset_origin}')\n",
    "\n",
    "for ax, model_name in zip(axs.flatten(), model_names):\n",
    "\n",
    "    for method in methods:\n",
    "        indices = df[\n",
    "            (df['dataset origin'] == dataset_origin) & (df['model'] == model_name) & (df['method'] == method)].index\n",
    "        ax.plot(df.loc[indices, 'dataset size'], df.loc[indices, metric], label=method)\n",
    "        ax.set_title(model_name)\n",
    "        ax.set_ylabel(metric)\n",
    "\n",
    "for ax in axs.flatten():\n",
    "    ax.legend()\n",
    "    ax.set_xlabel('calib subset size')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic data\n",
    "\n",
    "Synthetic data never improves ACE, rarely improves ECE. Filtering synthetic data is even worse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = 'ACE'\n",
    "\n",
    "for method in methods[1:]:\n",
    "    nb_synth_better = 0\n",
    "    nb_synth_filtered_better = 0\n",
    "    for model_name in model_names:\n",
    "\n",
    "        metric_value_validation = df.loc[\n",
    "            (df['dataset origin'] == 'validation') & (df['dataset size'] == 5000) & (df['method'] == method) & (df['model'] == model_name),\n",
    "            metric]\n",
    "        metric_value_synthetic = df.loc[\n",
    "            (df['dataset origin'] == 'synthetic') & (df['dataset size'] == 10000) & (df['method'] == method) & (df['model'] == model_name),\n",
    "            metric]\n",
    "        metric_value_synthetic_filtered = df.loc[\n",
    "            (df['dataset origin'] == 'synthetic filtered') & (df['dataset size'] == 10000) & (df['method'] == method) & (df['model'] == model_name),\n",
    "            metric]\n",
    "\n",
    "        nb_synth_better += (metric_value_synthetic.item() < metric_value_validation.item())\n",
    "        nb_synth_filtered_better += (metric_value_synthetic_filtered.item() < metric_value_synthetic.item())\n",
    "        \n",
    "    print(f'{method}: {nb_synth_better} / {len(model_names)} models better with synthetic data than with validation data')\n",
    "    print(f'{method}: {nb_synth_filtered_better} / {len(model_names)} models better with filtered synthetic data than with synthetic data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'vector scaling'\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(df.loc[(df['dataset origin'] == 'validation') & (df['method'] == method), 'ECE'], \n",
    "            df.loc[(df['dataset origin'] == 'validation') & (df['method'] == method), 'ACE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(df.loc[(df['dataset origin'] == 'validation') & (df['method'] == method), 'AUROC'], \n",
    "            df.loc[(df['dataset origin'] == 'validation') & (df['method'] == method), 'ECE'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is data augmentation useful?\n",
    "\n",
    "No, never improves compared to not-augmented validation data (same dataset size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = 'ECE'\n",
    "\n",
    "for method in methods[1:]:\n",
    "    nb_aug_better = 0\n",
    "    for model_name in model_names:\n",
    "\n",
    "        metric_value_validation = df.loc[\n",
    "            (df['dataset origin'] == 'validation') & (df['dataset size'] == 5000) & (df['method'] == method) & (df['model'] == model_name),\n",
    "            metric]\n",
    "        metric_value_synthetic = df.loc[\n",
    "            (df['dataset origin'] == 'validation augmented') & (df['dataset size'] == 5000) & (df['method'] == method) & (df['model'] == model_name),\n",
    "            metric]\n",
    "\n",
    "        nb_aug_better += (metric_value_synthetic.item() < metric_value_validation.item())\n",
    "        \n",
    "    print(f'{method}: {nb_synth_better} / {len(model_names)} models better with augmented data than with validation data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df['dataset origin'] == 'validation') & (df['dataset size'] == 5000) & (df['model'] == model_name)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df['dataset origin'] == 'validation augmented') & (df['dataset size'] == 5000) & (df['model'] == model_name)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = 'ACE'\n",
    "\n",
    "method = 'temperature scaling'\n",
    "metric_value_validation = df.loc[\n",
    "            (df['dataset origin'] == 'validation') & (df['dataset size'] == 5000) & (df['method'] == method) & (df['model'] == model_name),\n",
    "            metric]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_value_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = 'AUROC'\n",
    "\n",
    "metric_changes = {m: [] for m in ['temperature scaling', 'vector scaling']}\n",
    "for method in ['temperature scaling', 'vector scaling']:\n",
    "\n",
    "    for model_name in model_names:\n",
    "        \n",
    "        metric_after_calib = df.loc[\n",
    "            (df['dataset origin'] == 'validation') & (df['dataset size'] == 5000) & (df['method'] == method) & (df['model'] == model_name),\n",
    "            metric].item()\n",
    "\n",
    "        metric_before_calib = df.loc[\n",
    "            (df['dataset origin'] == 'validation') & (df['dataset size'] == 5000) & (df['method'] == 'baseline (no calibration)') & (df['model'] == model_name),\n",
    "            metric].item()\n",
    "\n",
    "        metric_changes[method].append(100*(metric_after_calib - metric_before_calib) / metric_before_calib)\n",
    "\n",
    "metric_changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
