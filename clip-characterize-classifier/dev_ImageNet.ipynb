{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision.transforms import Compose, Resize, Lambda, ToTensor, Grayscale, ToPILImage\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn')\n",
    "import PIL\n",
    "\n",
    "from imagenet_c import corrupt\n",
    "from CLIP import clip as clip_utils\n",
    "from utils import load_datasets_ImageNet_two_transforms\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "rng = np.random.default_rng(0)\n",
    "\n",
    "path_results = os.path.dirname(os.getcwd()) + '/results'\n",
    "path_dataset = os.path.expandvars('$DSDIR/imagenet') # '/scratchf/'\n",
    "path_imagenet_labels = os.path.expandvars('$WORK/DATA/LOC_synset_mapping.txt')\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD CLASSIFIER\n",
    "weights = ResNet50_Weights.IMAGENET1K_V2\n",
    "classifier = resnet50(weights=weights).to(device)\n",
    "preprocess_classif = weights.transforms()\n",
    "classifier.eval()\n",
    "\n",
    "# LOAD CLIP\n",
    "clip, preprocess_clip = clip_utils.load(\"ViT-B/32\", device=device)\n",
    "\n",
    "# LOAD DATA\n",
    "dataset_train, dataset_val = load_datasets_ImageNet_two_transforms(path_dataset, BATCH_SIZE, preprocess_classif, preprocess_clip)\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=BATCH_SIZE, num_workers=4, pin_memory=True, shuffle=False)   \n",
    "dataloader_val = DataLoader(dataset_val, batch_size=BATCH_SIZE, num_workers=4, pin_memory=True, shuffle=False)\n",
    "idx_to_label = {}\n",
    "with open(path_imagenet_labels) as f:\n",
    "    for i, line in enumerate(f):\n",
    "       idx_to_label[i] = line[10:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(path_results + '/logs_classif_val.csv'):\n",
    "    print('Load logs.')\n",
    "    df = pd.read_csv(path_results + '/logs_classif_val.csv', index_col=0)\n",
    "\n",
    "else:\n",
    "    print('Compute classification logs.')\n",
    "    df = pd.DataFrame(columns=['MSP', 'TCP', 'well_classified', 'pred_in_top5'], index=pd.RangeIndex(len(dataset_val)))\n",
    "    idx = 0\n",
    "    for batch in tqdm(dataloader_val):\n",
    "        (x_classif, y_classif), (x_clip, y_clip) = batch\n",
    "        assert (y_classif == y_clip).all(), \"data for classifier and CLIP is not the same\"\n",
    "        batch_size = x_classif.shape[0]\n",
    "        x_classif = x_classif.to(device)\n",
    "        y_classif = y_classif.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = classifier(x_classif)\n",
    "        probas = torch.nn.functional.softmax(logits, dim=1)\n",
    "        pred_top5 = logits.topk(5, dim=1).indices.t()\n",
    "\n",
    "        df.loc[idx:idx+batch_size-1, 'MSP'] = probas.max(1).values.cpu()\n",
    "        df.loc[idx:idx+batch_size-1, 'TCP'] = probas[torch.arange(batch_size), y_classif].cpu()\n",
    "        df.loc[idx:idx+batch_size-1, 'well_classified'] = (logits.argmax(dim=1) == y_classif).cpu()\n",
    "        df.loc[idx:idx+batch_size-1, 'pred_in_top5'] = pred_top5.eq(y_classif.expand_as(pred_top5)).sum(0).bool().cpu()\n",
    "\n",
    "        idx += batch_size\n",
    "\n",
    "    df.to_csv(path_results + '/logs_classif_val.csv')\n",
    "    print('Classification logs saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_errors_top1 = df.index[df['well_classified'] == False].tolist()\n",
    "idx_errors_top5 = df.index[df['pred_in_top5'] == False].tolist()\n",
    "\n",
    "dataset_val_errors_top1 = Subset(dataset_val, idx_errors_top1)\n",
    "dataset_val_errors_top5 = Subset(dataset_val, idx_errors_top5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples of misclassified, pred not in top 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=(12, 12))\n",
    "cols, rows = 3, 3\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(dataset_val_errors_top5), size=(1,)).item()\n",
    "    (img, label), _ = dataset_val_errors_top5[sample_idx]\n",
    "    pred = classifier(img.to(device).unsqueeze(0)).argmax(dim=1).item()\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(f'real: {idx_to_label[label]}\\npred: {idx_to_label[pred]}', fontsize=10)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow((0.2*img+0.4).permute(1, 2, 0), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selective classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline: max softmax\n",
    "domain_cutoff_baseline = np.linspace(0, 1, 1000)\n",
    "coverage_baseline = np.zeros_like(domain_cutoff_baseline)\n",
    "risk_baseline = np.zeros_like(domain_cutoff_baseline)\n",
    "acc_baseline = np.zeros_like(domain_cutoff_baseline)\n",
    "for i, cut in enumerate(domain_cutoff_baseline):\n",
    "    idx_domain = df['MSP'] > cut\n",
    "    coverage_baseline[i] = idx_domain.mean()\n",
    "    acc_baseline[i] = df.loc[idx_domain, 'well_classified'].mean()\n",
    "\n",
    "# plot\n",
    "fig, (ax1) = plt.subplots(1, 1, figsize=(10, 5))\n",
    "ax1.set_title(f'coverage vs. accuracy')\n",
    "sc = ax1.scatter(coverage_baseline, acc_baseline, c=domain_cutoff_baseline, cmap='viridis')\n",
    "fig.colorbar(sc, ax=ax1, label='MSP threshold')\n",
    "ax1.set_xlabel('coverage')\n",
    "ax1.set_ylabel('accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_per_class = []\n",
    "mean_msp_per_class = []\n",
    "for class_idx in range(1000):\n",
    "    acc_per_class.append(df.loc[np.array(dataset_val.imagenet_data_1.targets) == class_idx, 'well_classified'].mean())\n",
    "    mean_msp_per_class.append(df.loc[np.array(dataset_val.imagenet_data_1.targets) == class_idx, 'MSP'].mean())\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(acc_per_class)\n",
    "plt.xlabel('accuracy per class')\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(mean_msp_per_class)\n",
    "plt.xlabel('mean MSP per class')\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(mean_msp_per_class, acc_per_class)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (main, Nov  4 2022, 13:48:29) [GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c522a5618233109531e8d8fb7f5c3011399924e76f9423af51315557ed1c4c11"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
